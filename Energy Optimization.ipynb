{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "cdat = pd.read_csv('Texas_Counties.csv', usecols=['County']) #all 254 counties in TX\n",
    "counties = cdat['County'].to_list()\n",
    "\n",
    "non_ercot_counties = ['El Paso','Hudspeth','Gaines','Terry','Yoakum','Cochran','Hockley','Lubbock','Bailey',\n",
    "                      'Lamb','Hartley','Dallam','Moore','Sherman','Hansford','Hutchinson','Ochiltree','Lipscomb', \n",
    "                      'Hemphill','Bowie','Morris','Cass','Camp','Marion','Upshur','Gregg','Harrison','Panola',\n",
    "                      'Shelby','San Augustine','Sabine','Trinity','Polk','Tyler','Jasper','Newton','San Jacinto',\n",
    "                      'Hardin','Liberty','Orange','Jefferson']\n",
    "remove_counties = [count + ' County' for count in non_ercot_counties]\n",
    "\n",
    "for count in remove_counties:\n",
    "    counties.remove(count)\n",
    "\n",
    "print(len(counties))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALYZING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coal data - if doing leave one out cross test, only use 2 years of coal data\n",
    "coal = pd.read_csv('ERCOT/Coal2019.csv',usecols=['Coal']).to_numpy().flatten()\n",
    "coalhours = np.hstack((coal,coal,coal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure 5 (and supplement)\n",
    "days = np.array([31,28,31,30,31,30,31,31,30,31,30,31]); halfhours = days*48; hsums = []\n",
    "for month in range(12):\n",
    "    hsums.append(sum(halfhours[:month]))\n",
    "hsums.append(17520)\n",
    "months = ['January','February','March','April','May','June','July','August','September','October','November','December']\n",
    "\n",
    "outdic = {}\n",
    "for m in range(12):\n",
    "    avg = np.empty(48)\n",
    "    month = coalhours[hsums[m]:hsums[m+1]]\n",
    "    for hh in range(48):\n",
    "        avg[hh] = sum(month[hh::48]) / days[m]\n",
    "    outdic[months[m]] = avg\n",
    "pd.DataFrame(data=outdic).to_csv('CoalDays.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import formatted power data and stack for 3 years. Analyzing output within each county\n",
    "cnum = len(counties)\n",
    "solarcsvs = ['Solar/Solar2009.csv','Solar/Solar2010.csv','Solar/Solar2011.csv']\n",
    "solartraincsvs = solarcsvs\n",
    "solartestcsvs = []\n",
    "solarpower = np.empty((cnum,0))\n",
    "solarpowertest = np.empty((cnum,0))\n",
    "\n",
    "#test/train split the csvs if you want to do leave one out cross-test analysis\n",
    "for solarcsv in solartraincsvs:\n",
    "    pdat = pd.read_csv(solarcsv, usecols=counties)\n",
    "    solaryear = pdat[counties[0]].to_numpy() #0th\n",
    "    for i in range(cnum-1): #1th onwards\n",
    "        solaryear = np.vstack((solaryear,pdat[counties[i+1]].to_numpy()))\n",
    "    solarpower = np.concatenate((solarpower,solaryear),axis=1) #div by 2 to convert from MW (power) to MWh (energy output)\n",
    "\n",
    "for solarcsv in solartestcsvs:\n",
    "    pdat = pd.read_csv(solarcsv, usecols=counties)\n",
    "    solaryear = pdat[counties[0]].to_numpy() #0th\n",
    "    for i in range(cnum-1): #1th onwards\n",
    "        solaryear = np.vstack((solaryear,pdat[counties[i+1]].to_numpy()))\n",
    "    solarpowertest = np.concatenate((solarpowertest,solaryear),axis=1)\n",
    "\n",
    "#NEED TO PUT IN WIND2011.csv\n",
    "windcsvs = ['Wind/Wind2009.csv','Wind/Wind2010.csv','Wind/Wind2010.csv']\n",
    "windtraincsvs = windcsvs\n",
    "windtestcsvs = []\n",
    "windpower = np.empty((cnum,0))\n",
    "windpowertest = np.empty((cnum,0))\n",
    "\n",
    "for windcsv in windtraincsvs:\n",
    "    pdat = pd.read_csv(windcsv, usecols=counties)\n",
    "    windyear = pdat[counties[0]].to_numpy() #0th\n",
    "    for i in range(cnum-1): #1th onwards\n",
    "        windyear = np.vstack((windyear,pdat[counties[i+1]].to_numpy()))\n",
    "    windpower = np.concatenate((windpower,windyear),axis=1)\n",
    "    \n",
    "for windcsv in windtestcsvs:\n",
    "    pdat = pd.read_csv(windcsv, usecols=windcounts)\n",
    "    windyear = pdat[counties[0]].to_numpy() #0th\n",
    "    for i in range(cnum-1): #1th onwards\n",
    "        windyear = np.vstack((windyear,pdat[counties[i+1]].to_numpy()))\n",
    "    windpowertest = np.concatenate((windpowertest,windyear),axis=1)\n",
    "    \n",
    "solarpower = np.transpose(solarpower)\n",
    "windpower = np.transpose(windpower)\n",
    "solarpowertest = np.transpose(solarpowertest)\n",
    "windpowertest = np.transpose(windpowertest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure 6 - this csv file can be used to make the map\n",
    "sp = sum(solarpower) / 52560\n",
    "wp = sum(windpower) / 52560\n",
    "outdic = {'County': counties, 'Solar': 2*sp, 'Wind': 2*wp}\n",
    "pd.DataFrame(data=outdic).to_csv('AverageCF_County.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUNNING OPTIMIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262\n",
      "108\n",
      "58014.529999999984\n",
      "24588.49\n",
      "610.0\n",
      "630.0\n"
     ]
    }
   ],
   "source": [
    "#USING GIS REPORT\n",
    "\n",
    "#import GIS site data\n",
    "gisreport = 'ERCOT/Ercot_GIS_Report_June.xlsx'\n",
    "pdat = pd.read_excel(gisreport, sheet_name='Project Details', usecols=['GINR Study Phase','County','Fuel','Capacity (MW)'])\n",
    "\n",
    "solarp = pdat.loc[pdat['Fuel']==\"SOL\"]\n",
    "solarp = solarp.loc[solarp['Capacity (MW)'] > 0] #some caps 0 - don't need to remove technically but y not\n",
    "\n",
    "ogsolarcounts = solarp['County'].to_list()\n",
    "solarcounts = [count + ' County' for count in ogsolarcounts]\n",
    "solarcaps = solarp['Capacity (MW)'].to_numpy()\n",
    "solarcnum = len(solarcounts)\n",
    "\n",
    "windp = pdat.loc[pdat['Fuel']==\"WIN\"]\n",
    "windp = windp.loc[windp['Capacity (MW)'] > 0] \n",
    "\n",
    "ogwindcounts = windp['County'].to_list()\n",
    "windcounts = [count + ' County' for count in ogwindcounts]\n",
    "windcaps = windp['Capacity (MW)'].to_numpy()\n",
    "windcnum = len(windcounts)\n",
    "\n",
    "solarnames = [solarcounts[i] + ' Solar: ' + str(solarcaps[i]) for i in range(solarcnum)]\n",
    "windnames = [windcounts[i] + ' Wind: ' + str(windcaps[i]) for i in range(windcnum)] \n",
    "\n",
    "####for checking if things ran correctly\n",
    "print(solarcnum)\n",
    "print(windcnum)\n",
    "\n",
    "print(sum(solarcaps))\n",
    "print(sum(windcaps))\n",
    "print(max(solarcaps))\n",
    "print(max(windcaps))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure 4 - Study Phase info\n",
    "#import GIS site data\n",
    "gisreport = 'ERCOT/Ercot_GIS_Report_June.xlsx'\n",
    "pdat = pd.read_excel(gisreport, sheet_name='Project Details', usecols=['GINR Study Phase','County','Fuel','Capacity (MW)'])\n",
    "\n",
    "solarp = pdat.loc[pdat['Fuel']==\"SOL\"]\n",
    "solarp = solarp.loc[solarp['Capacity (MW)'] > 0] #some caps 0 - don't need to remove technically but y not\n",
    "solarcaps = solarp['Capacity (MW)'].to_numpy()\n",
    "sphase = solarp['GINR Study Phase'].to_list()\n",
    "\n",
    "windp = pdat.loc[pdat['Fuel']==\"WIN\"]\n",
    "windp = windp.loc[windp['Capacity (MW)'] > 0] \n",
    "windcaps = windp['Capacity (MW)'].to_numpy()\n",
    "wphase = windp['GINR Study Phase'].to_list()\n",
    "\n",
    "spd = defaultdict(int)\n",
    "wpd = defaultdict(int)\n",
    "\n",
    "for i in range(len(solarcaps)):\n",
    "    phase = sphase[i]\n",
    "    cap = solarcaps[i]\n",
    "    spd[phase] += float(cap)\n",
    "for i in range(len(windcaps)):\n",
    "    phase = wphase[i]\n",
    "    cap = windcaps[i]\n",
    "    wpd[phase] += float(cap)\n",
    "    \n",
    "pd.DataFrame(data=[spd,wpd]).to_excel('StudyPhaseOut.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import formatted power data and scale up by site capacity, put in matrix form\n",
    "solarcsvs = ['Solar/Solar2009.csv','Solar/Solar2010.csv','Solar/Solar2011.csv']\n",
    "solartraincsvs = solarcsvs\n",
    "solartestcsvs = []\n",
    "solarpower = np.empty((solarcnum,0))\n",
    "solarpowertest = np.empty((solarcnum,0))\n",
    "hl = 0.5 #working with half hours so hour-length = 0.5\n",
    "\n",
    "#test/train split the csvs if you want to do leave one out cross-test analysis\n",
    "for solarcsv in solartraincsvs:\n",
    "    pdat = pd.read_csv(solarcsv, usecols=solarcounts)\n",
    "    solaryear = pdat[solarcounts[0]].to_numpy() * solarcaps[0] * hl #0th\n",
    "    for i in range(solarcnum-1): #1th onwards\n",
    "        solaryear = np.vstack((solaryear,pdat[solarcounts[i+1]].to_numpy() * solarcaps[i+1] * hl))\n",
    "    solarpower = np.concatenate((solarpower,solaryear),axis=1) #div by 2 to convert from MW (power) to MWh (energy output)\n",
    "\n",
    "for solarcsv in solartestcsvs:\n",
    "    pdat = pd.read_csv(solarcsv, usecols=solarcounts)\n",
    "    solaryear = pdat[solarcounts[0]].to_numpy() * solarcaps[0] * hl #0th\n",
    "    for i in range(solarcnum-1): #1th onwards\n",
    "        solaryear = np.vstack((solaryear,pdat[solarcounts[i+1]].to_numpy() * solarcaps[i+1] * hl))\n",
    "    solarpowertest = np.concatenate((solarpowertest,solaryear),axis=1)\n",
    "\n",
    "#NEED TO PUT IN WIND2011.csv\n",
    "windcsvs = ['Wind/Wind2009.csv','Wind/Wind2010.csv','Wind/Wind2010.csv']\n",
    "windtraincsvs = windcsvs\n",
    "windtestcsvs = []\n",
    "windpower = np.empty((windcnum,0))\n",
    "windpowertest = np.empty((windcnum,0))\n",
    "\n",
    "for windcsv in windtraincsvs:\n",
    "    pdat = pd.read_csv(windcsv, usecols=windcounts)\n",
    "    windyear = pdat[windcounts[0]].to_numpy() * windcaps[0] * hl #0th\n",
    "    for i in range(windcnum-1): #1th onwards\n",
    "        windyear = np.vstack((windyear,pdat[windcounts[i+1]].to_numpy() * windcaps[i+1] * hl))\n",
    "    windpower = np.concatenate((windpower,windyear),axis=1)\n",
    "    \n",
    "for windcsv in windtestcsvs:\n",
    "    pdat = pd.read_csv(windcsv, usecols=windcounts)\n",
    "    windyear = pdat[windcounts[0]].to_numpy() * windcaps[0] * hl #0th\n",
    "    for i in range(windcnum-1): #1th onwards\n",
    "        windyear = np.vstack((windyear,pdat[windcounts[i+1]].to_numpy() * windcaps[i+1] * hl))\n",
    "    windpowertest = np.concatenate((windpowertest,windyear),axis=1)\n",
    "    \n",
    "solarpower = np.transpose(solarpower)\n",
    "windpower = np.transpose(windpower)\n",
    "solarpowertest = np.transpose(solarpowertest)\n",
    "windpowertest = np.transpose(windpowertest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure 7 - Monthly regional capacity factor --> first get regional info then use to make monthly graphs\n",
    "simpregdict = pd.read_csv('CountyToRegion.csv')\n",
    "regions = np.array(['NORTH', 'NCENT', 'EAST', 'COAST', 'SOUTH', 'SCENT', 'WEST', 'FWEST']) #easier if numpy array\n",
    "\n",
    "y = 17520\n",
    "n = 3*y\n",
    "solarregout = dict.fromkeys(regions,np.zeros(y)) #every half-hour\n",
    "solarregcap = dict.fromkeys(regions,0)\n",
    "windregout = dict.fromkeys(regions,np.zeros(y))\n",
    "windregcap = dict.fromkeys(regions,0)\n",
    "\n",
    "#if you want to analyze all GIS sites use this\n",
    "solarout = counties\n",
    "windout = counties\n",
    "\n",
    "for site in solarout:\n",
    "    i = solarnames.index(site)\n",
    "    sitepower = solarpower[:,i]\n",
    "    cap = solarcaps[i]\n",
    "    county = solarcounts[i]\n",
    "    reg = simpregdict[county][0]\n",
    "    avpower = (sitepower[0:y] + sitepower[y:(2*y)] + sitepower[(2*y):(3*y)])/3\n",
    "    solarregout[reg] = solarregout[reg] + avpower #((sitepower[::2] + sitepower[1::2]) / 1) #divide by 2 b/c want avg power (if MWh don't)\n",
    "    solarregcap[reg] = solarregcap[reg] + cap\n",
    "    \n",
    "for site in windout:\n",
    "    i = windnames.index(site)\n",
    "    sitepower = windpower[:,i]\n",
    "    cap = windcaps[i]\n",
    "    county = windcounts[i]\n",
    "    reg = simpregdict[county][0]\n",
    "    avpower = (sitepower[0:y] + sitepower[y:(2*y)] + sitepower[(2*y):(3*y)])/3\n",
    "    windregout[reg] = windregout[reg] + avpower\n",
    "    windregcap[reg] = windregcap[reg] + cap\n",
    "    \n",
    "solarregcf = {}\n",
    "windregcf = {}\n",
    "regcap = {}\n",
    "for reg in regions:\n",
    "    solarregcf[reg] = 2*solarregout[reg] / solarregcap[reg]\n",
    "    windregcf[reg] = 2*windregout[reg] / windregcap[reg]\n",
    "    regcap[reg] = [solarregcap[reg],windregcap[reg]]    \n",
    "#pd.DataFrame(data=regcap).to_csv('RegOut.csv')\n",
    "\n",
    "#Figure 7 - Monthly regional capacity factor\n",
    "smregs = {}\n",
    "wmregs = {}\n",
    "cmregs = {}\n",
    "\n",
    "targetregs = ['NORTH','COAST','SOUTH','FWEST']\n",
    "for month in range(12):\n",
    "    outdic = {}\n",
    "    for reg in targetregs:\n",
    "        solaryear = solarregcf[reg]\n",
    "        windyear = windregcf[reg]\n",
    "        solarmonth = solaryear[hsums[month]:hsums[month+1]]\n",
    "        windmonth = windyear[hsums[month]:hsums[month+1]]\n",
    "        solarday = np.empty(48)\n",
    "        windday = np.empty(48)\n",
    "        for hh in range(48):\n",
    "            solarday[hh] = sum(solarmonth[hh::48]) / days[month]\n",
    "            windday[hh] = sum(windmonth[hh::48]) / days[month]\n",
    "        outdic[reg + 'Solar'] = solarday\n",
    "        outdic[reg + 'Wind'] = windday\n",
    "    pd.DataFrame(data=outdic).to_csv(months[month]+'.csv') #this will create 12 csvs for each month, combine into one sheet after\n",
    "        \n",
    "# pd.DataFrame(data=smregs).to_csv('SolarMonthlyCF.csv')\n",
    "# pd.DataFrame(data=wmregs).to_csv('WindMonthlyCF.csv')\n",
    "# pd.DataFrame(data=cmregs).to_csv('CoalMonthlyCF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost data\n",
    "sc = 92.50*1000 # LCOE $ / MW-Cap \n",
    "solarcost = sc*solarcaps\n",
    "wc = 118.48*1000 # LCOE $ / MW-Cap \n",
    "windcost = wc*windcaps\n",
    "#coalcost = 111.67 # $ / MWh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel = 'ERCOT/Fuel2019.xlsx'\n",
    "months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "xls = pd.ExcelFile(fuel)\n",
    "\n",
    "coalhours = np.empty(0)\n",
    "\n",
    "for i in range(12):\n",
    "    dat = pd.read_excel(xls, months[i])\n",
    "    coal = dat.loc[dat['Fuel']==\"Coal\"]\n",
    "    coal = coal[coal.columns[4::2]].to_numpy() + coal[coal.columns[5::2]].to_numpy() #every half hour\n",
    "    coal = np.reshape(coal,np.prod(coal.shape))\n",
    "    coalhours = np.concatenate((coalhours,coal))\n",
    "coalhours = np.nan_to_num(coalhours)\n",
    "coalhours = np.hstack((coalhours,coalhours,coalhours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model timespan: 3.0 years\n",
      "There are a total of 58014.529999999984 MW of solar capacity in GIS queue\n",
      "There are a total of 24588.49 MW of wind capacity in GIS queue\n",
      "Building all solar sites (and no wind) can cover: 52.53644870668295 % of coal output\n",
      "Building all wind sites (and no solar) can cover: 78.0965847877315 % of coal output\n",
      "Building all wind and solar sites can cover: 96.18286520350973 % of coal output\n",
      "Building all sites can cover coal output on: 88.90981735159818 % of half-hours\n",
      "Building all sites would cost: $ 8.2795883202 billion\n",
      "(52560,)\n"
     ]
    }
   ],
   "source": [
    "#Exploratory analysis\n",
    "coaltotal = sum(coalhours)\n",
    "h = len(coalhours)\n",
    "\n",
    "#for continouous\n",
    "#s_maxcap = 610; w_maxcap = 630\n",
    "#spv = s_maxcap*np.sum(solarpower, axis=1); wpv = w_maxcap*np.sum(windpower, axis=1);\n",
    "spv = np.sum(solarpower, axis=1); wpv = np.sum(windpower, axis=1);\n",
    "allpower = spv + wpv\n",
    "\n",
    "sd = coalhours - spv\n",
    "wd = coalhours - wpv\n",
    "dif = coalhours - allpower\n",
    "sinf = sum(sd[sd > 0])\n",
    "winf = sum(wd[wd > 0])\n",
    "infeasibility = sum(dif[dif > 0]) \n",
    "infhours = sum(dif > 0)\n",
    "\n",
    "print(\"Model timespan:\", h / (48*365), \"years\")\n",
    "print(\"There are a total of\", sum(solarcaps), \"MW of solar capacity in GIS queue\")\n",
    "print(\"There are a total of\", sum(windcaps), \"MW of wind capacity in GIS queue\")\n",
    "print(\"Building all solar sites (and no wind) can cover:\", 100*(1 - (sinf / coaltotal)), \"% of coal output\")\n",
    "print(\"Building all wind sites (and no solar) can cover:\", 100*(1 - (winf / coaltotal)), \"% of coal output\")\n",
    "print(\"Building all wind and solar sites can cover:\", 100*(1 - (infeasibility / coaltotal)), \"% of coal output\")\n",
    "print(\"Building all sites can cover coal output on:\", 100*(1 - (infhours / h)), \"% of half-hours\")\n",
    "print(\"Building all sites would cost: $\", (sum(solarcost) + sum(windcost)) / 10**9, \"billion\")\n",
    "\n",
    "print(coalhours.shape)\n",
    "slackcap = (max(coalhours))\n",
    "slacknames = ['Slack:' + str(i) for i in range(h)] #for naming slack variables in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using license file /Users/richard.morse/gurobi.lic\n",
      "Academic license - for non-commercial use only - expires 2021-07-22\n",
      "Gurobi Optimizer version 9.1.0 build v9.1.0rc0 (mac64)\n",
      "Thread count: 2 physical cores, 4 logical processors, using up to 4 threads\n",
      "Optimize a model with 52561 rows, 52930 columns and 19393555 nonzeros\n",
      "Model fingerprint: 0x71ced68e\n",
      "Variable types: 52560 continuous, 370 integer (370 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [3e-06, 3e+02]\n",
      "  Objective range  [2e+05, 7e+07]\n",
      "  Bounds range     [1e+00, 7e+03]\n",
      "  RHS range        [1e+03, 2e+07]\n",
      "Found heuristic solution: objective 7.909265e+09\n",
      "Presolve removed 0 rows and 0 columns (presolve time = 6s) ...\n",
      "Presolve removed 0 rows and 28 columns (presolve time = 48s) ...\n",
      "Presolve removed 0 rows and 28 columns (presolve time = 50s) ...\n",
      "Presolve removed 5303 rows and 5331 columns (presolve time = 64s) ...\n",
      "Presolve removed 5303 rows and 5331 columns (presolve time = 65s) ...\n",
      "Presolve removed 5303 rows and 5333 columns (presolve time = 110s) ...\n",
      "Presolve removed 5303 rows and 5333 columns (presolve time = 121s) ...\n",
      "Presolve removed 5303 rows and 5333 columns (presolve time = 145s) ...\n",
      "Presolve removed 5598 rows and 5628 columns (presolve time = 151s) ...\n",
      "Presolve removed 5292 rows and 5322 columns\n",
      "Presolve time: 150.52s\n",
      "Presolved: 47269 rows, 47608 columns, 14974207 nonzeros\n",
      "Variable types: 47257 continuous, 351 integer (321 binary)\n",
      "\n",
      "Deterministic concurrent LP optimizer: dual simplex and barrier\n",
      "Showing barrier log only...\n",
      "\n",
      "Root barrier log...\n",
      "\n",
      "Ordering time: 0.84s\n",
      "\n",
      "Barrier statistics:\n",
      " Dense cols : 347\n",
      " AA' NZ     : 1.474e+07\n",
      " Factor NZ  : 1.533e+07 (roughly 170 MBytes of memory)\n",
      " Factor Ops : 4.993e+09 (less than 1 second per iteration)\n",
      " Threads    : 1\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   8.91128607e+12 -3.63900132e+12  1.48e+07 1.20e+03  5.84e+09   183s\n",
      "   1   5.17856702e+12 -3.61185789e+12  8.46e+06 1.49e+05  3.10e+09   185s\n",
      "   2   3.57397096e+12 -3.61214138e+12  5.49e+06 5.07e+04  1.86e+09   187s\n",
      "   3   2.96152275e+12 -3.62439070e+12  4.46e+06 2.92e+04  1.45e+09   189s\n",
      "   4   1.44210459e+12 -3.73072175e+12  2.11e+06 5.51e+03  6.49e+08   191s\n",
      "   5   4.89692492e+11 -3.50283103e+12  5.47e+05 2.76e+02  1.76e+08   193s\n",
      "   6   2.41052614e+11 -2.57476447e+12  2.26e+05 9.18e-06  7.26e+07   195s\n",
      "   7   2.90935065e+10 -1.07693916e+12  2.02e+04 3.69e-05  1.11e+07   197s\n",
      "   8   1.14602572e+10 -2.38666970e+11  3.51e+03 2.40e-05  2.02e+06   199s\n",
      "   9   8.70468774e+09 -1.35630141e+11  1.26e+03 2.63e-05  1.07e+06   202s\n",
      "  10   8.14148745e+09 -1.04989791e+11  1.03e+03 6.50e-05  8.28e+05   204s\n",
      "  11   7.17905379e+09 -8.23293903e+10  7.64e+02 5.50e-05  6.48e+05   206s\n",
      "  12   7.03470204e+09 -7.11542297e+10  7.29e+02 4.70e-05  5.65e+05   208s\n",
      "  13   6.21471851e+09 -4.83108132e+10  5.09e+02 3.64e-05  3.90e+05   210s\n",
      "  14   5.70904877e+09 -2.84398647e+10  3.65e+02 3.36e-05  2.43e+05   213s\n",
      "  15   5.06971749e+09 -2.09794348e+10  2.15e+02 2.54e-05  1.84e+05   215s\n",
      "  16   4.78254112e+09 -1.31991701e+10  1.52e+02 1.73e-05  1.27e+05   217s\n",
      "  17   4.72341221e+09 -1.16092114e+10  1.41e+02 1.59e-05  1.15e+05   219s\n",
      "  18   4.45790206e+09 -8.72341387e+09  8.60e+01 1.29e-05  9.26e+04   225s\n",
      "  19   4.36424116e+09 -6.00216372e+09  6.22e+01 1.02e-05  7.27e+04   227s\n",
      "  20   4.19497396e+09 -3.71262538e+09  2.57e+01 7.69e-06  5.54e+04   229s\n",
      "  21   4.10238753e+09 -1.40926492e+09  1.53e-01 5.45e-06  3.87e+04   231s\n",
      "  22   4.03382769e+09 -8.02268513e+07  1.39e-01 3.79e-06  2.88e+04   233s\n",
      "  23   3.86619182e+09  3.87873642e+08  1.01e-01 3.32e-06  2.44e+04   234s\n",
      "  24   3.76478589e+09  9.35686486e+08  9.08e-02 2.57e-06  1.98e+04   236s\n",
      "  25   3.69909391e+09  1.37636432e+09  8.49e-02 1.98e-06  1.63e+04   238s\n",
      "  26   3.63962081e+09  1.55304861e+09  7.88e-02 1.73e-06  1.46e+04   239s\n",
      "  27   3.62210631e+09  1.73250391e+09  7.70e-02 1.48e-06  1.32e+04   241s\n",
      "  28   3.49684540e+09  1.88419639e+09  6.66e-02 1.23e-06  1.13e+04   242s\n",
      "  29   3.47143183e+09  2.08861354e+09  6.38e-02 9.66e-07  9.68e+03   244s\n",
      "  30   3.44010006e+09  2.21207973e+09  6.07e-02 7.86e-07  8.60e+03   246s\n",
      "  31   3.29110099e+09  2.33500661e+09  4.51e-02 5.96e-07  6.69e+03   248s\n",
      "  32   3.27729351e+09  2.37680978e+09  4.38e-02 5.51e-07  6.30e+03   250s\n",
      "  33   3.22242533e+09  2.48136593e+09  3.90e-02 4.20e-07  5.19e+03   252s\n",
      "  34   3.20057901e+09  2.55393171e+09  3.71e-02 3.05e-07  4.52e+03   253s\n",
      "  35   3.08627388e+09  2.60491514e+09  2.60e-02 2.19e-07  3.37e+03   255s\n",
      "  36   3.07334997e+09  2.65972897e+09  2.47e-02 1.69e-07  2.89e+03   257s\n",
      "  37   3.06437268e+09  2.68330156e+09  2.39e-02 1.52e-07  2.67e+03   259s\n",
      "  38   2.95484344e+09  2.71540623e+09  1.36e-02 1.29e-07  1.68e+03   261s\n",
      "  39   2.93836078e+09  2.73300995e+09  1.23e-02 8.82e-08  1.44e+03   263s\n",
      "  40   2.88906526e+09  2.77157755e+09  7.37e-03 7.94e-08  8.22e+02   265s\n",
      "  41   2.85533415e+09  2.78703806e+09  4.02e-03 6.05e-08  4.78e+02   267s\n",
      "  42   2.83988385e+09  2.79900851e+09  2.59e-03 6.61e-08  2.86e+02   269s\n",
      "  43   2.83148113e+09  2.80086465e+09  1.81e-03 3.54e-08  2.14e+02   270s\n",
      "  44   2.82453646e+09  2.80318230e+09  1.18e-03 6.98e-08  1.49e+02   272s\n",
      "  45   2.81988257e+09  2.80433850e+09  7.51e-04 6.24e-08  1.09e+02   274s\n",
      "  46   2.81679290e+09  2.80894029e+09  4.86e-04 7.08e-08  5.49e+01   276s\n",
      "  47   2.81436526e+09  2.81031998e+09  2.82e-04 4.24e-08  2.83e+01   279s\n",
      "  48   2.81295113e+09  2.81069400e+09  1.59e-04 8.38e-08  1.58e+01   281s\n",
      "  49   2.81161655e+09  2.81086877e+09  4.82e-05 4.84e-08  5.23e+00   283s\n",
      "  50   2.81133462e+09  2.81090193e+09  2.85e-05 6.05e-08  3.03e+00   285s\n",
      "  51   2.81113079e+09  2.81091422e+09  2.33e-05 5.87e-08  1.51e+00   287s\n",
      "  52   2.81105371e+09  2.81094702e+09  1.28e-05 4.66e-08  7.46e-01   289s\n",
      "  53   2.81100728e+09  2.81095114e+09  6.44e-06 4.28e-08  3.93e-01   291s\n",
      "  54   2.81097327e+09  2.81095548e+09  2.05e-06 9.41e-08  1.24e-01   294s\n",
      "  55   2.81095749e+09  2.81095710e+09  2.66e-08 6.52e-08  2.75e-03   296s\n",
      "  56   2.81095731e+09  2.81095726e+09  3.52e-09 3.68e-04  3.50e-04   299s\n",
      "  57   2.81095729e+09  2.81095729e+09  9.31e-11 3.63e-05  7.58e-07   300s\n",
      "  58   2.81095729e+09  2.81095729e+09  4.87e-09 1.43e-05  1.90e-07   302s\n",
      "  59   2.81095729e+09  2.81095729e+09  2.99e-09 9.90e-07  1.90e-10   304s\n",
      "\n",
      "Barrier solved model in 59 iterations and 304.12 seconds\n",
      "Optimal objective 2.81095729e+09\n",
      "\n",
      "\n",
      "Root crossover log...\n",
      "\n",
      "      20 DPushes remaining with DInf 0.0000000e+00               305s\n",
      "       0 DPushes remaining with DInf 0.0000000e+00               306s\n",
      "\n",
      "      15 PPushes remaining with PInf 0.0000000e+00               306s\n",
      "       0 PPushes remaining with PInf 0.0000000e+00               307s\n",
      "\n",
      "  Push phase complete: Pinf 0.0000000e+00, Dinf 2.5701144e-07    307s\n",
      "\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "      38    2.8109573e+09   0.000000e+00   0.000000e+00    308s\n",
      "      38    2.8109573e+09   0.000000e+00   0.000000e+00    310s\n",
      "Concurrent spin time: 0.00s\n",
      "\n",
      "Solved with barrier\n",
      "\n",
      "Root relaxation: objective 2.810957e+09, 38 iterations, 147.02 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.8110e+09    0    8 7.9093e+09 2.8110e+09  64.5%     -  311s\n",
      "H    0     0                    2.908742e+09 2.8110e+09  3.36%     -  335s\n",
      "     0     0 2.8110e+09    0   10 2.9087e+09 2.8110e+09  3.36%     -  347s\n",
      "H    0     0                    2.815307e+09 2.8110e+09  0.15%     -  355s\n",
      "     0     0 2.8110e+09    0   10 2.8153e+09 2.8110e+09  0.15%     -  359s\n",
      "     0     0 2.8110e+09    0   12 2.8153e+09 2.8110e+09  0.15%     -  375s\n",
      "     0     0 2.8110e+09    0    9 2.8153e+09 2.8110e+09  0.15%     -  382s\n",
      "     0     0 2.8110e+09    0   10 2.8153e+09 2.8110e+09  0.15%     -  421s\n",
      "     0     0 2.8110e+09    0   10 2.8153e+09 2.8110e+09  0.15%     -  429s\n",
      "     0     0 2.8110e+09    0   11 2.8153e+09 2.8110e+09  0.15%     -  475s\n",
      "     0     0 2.8110e+09    0   14 2.8153e+09 2.8110e+09  0.15%     -  482s\n",
      "     0     0 2.8110e+09    0   12 2.8153e+09 2.8110e+09  0.15%     -  502s\n",
      "     0     0 2.8110e+09    0   12 2.8153e+09 2.8110e+09  0.15%     -  522s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H    0     0                    2.812361e+09 2.8110e+09  0.05%     -  527s\n",
      "     0     0 2.8110e+09    0    8 2.8124e+09 2.8110e+09  0.05%     - 3009s\n",
      "     0     0 2.8110e+09    0   10 2.8124e+09 2.8110e+09  0.05%     - 3021s\n",
      "     0     0 2.8110e+09    0   11 2.8124e+09 2.8110e+09  0.05%     - 3027s\n",
      "     0     0 2.8110e+09    0   10 2.8124e+09 2.8110e+09  0.05%     - 3031s\n",
      "     0     0 2.8110e+09    0   11 2.8124e+09 2.8110e+09  0.05%     - 3035s\n",
      "     0     0 2.8110e+09    0   12 2.8124e+09 2.8110e+09  0.05%     - 3047s\n",
      "     0     0 2.8110e+09    0   11 2.8124e+09 2.8110e+09  0.05%     - 3054s\n",
      "     0     0 2.8110e+09    0   11 2.8124e+09 2.8110e+09  0.05%     - 3057s\n",
      "     0     0 2.8110e+09    0   13 2.8124e+09 2.8110e+09  0.05%     - 3082s\n",
      "     0     0 2.8110e+09    0   12 2.8124e+09 2.8110e+09  0.05%     - 3088s\n",
      "     0     0 2.8110e+09    0   15 2.8124e+09 2.8110e+09  0.05%     - 3113s\n",
      "     0     0 2.8110e+09    0   14 2.8124e+09 2.8110e+09  0.05%     - 3120s\n",
      "     0     0 2.8110e+09    0   14 2.8124e+09 2.8110e+09  0.05%     - 3131s\n",
      "     0     2 2.8110e+09    0   14 2.8124e+09 2.8110e+09  0.05%     - 3161s\n",
      "     1     5 2.8110e+09    1    9 2.8124e+09 2.8110e+09  0.05%   153 3168s\n",
      "     3     6 2.8110e+09    2    7 2.8124e+09 2.8110e+09  0.05%   126 3173s\n",
      "     7    10 2.8110e+09    3    8 2.8124e+09 2.8110e+09  0.05%  64.6 3176s\n",
      "    15    19 2.8110e+09    5    8 2.8124e+09 2.8110e+09  0.05%  39.6 3181s\n",
      "    18    26 2.8112e+09    6    8 2.8124e+09 2.8110e+09  0.05%  50.5 3187s\n",
      "    25    40 2.8110e+09    7    6 2.8124e+09 2.8110e+09  0.05%  39.0 3197s\n",
      "    39    69 2.8110e+09   14    3 2.8124e+09 2.8110e+09  0.05%  30.2 3216s\n",
      "    68   118 2.8111e+09   28    1 2.8124e+09 2.8110e+09  0.05%  25.4 3248s\n",
      "H   87   118                    2.811611e+09 2.8110e+09  0.02%  21.1 3248s\n",
      "   120   180 2.8112e+09   55    2 2.8116e+09 2.8110e+09  0.02%  17.3 3293s\n",
      "H  131   175                    2.811255e+09 2.8110e+09  0.01%  16.1 3293s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 1\n",
      "  MIR: 21\n",
      "  RLT: 4\n",
      "\n",
      "Explored 224 nodes (2947 simplex iterations) in 3294.61 seconds\n",
      "Thread count was 4 (of 4 available processors)\n",
      "\n",
      "Solution count 6: 2.81126e+09 2.81161e+09 2.81236e+09 ... 7.90927e+09\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.811255390000e+09, best bound 2.811000571806e+09, gap 0.0091%\n"
     ]
    }
   ],
   "source": [
    "#setting up model and solving\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "m = gp.Model(\"coal\")\n",
    "\n",
    "#vars\n",
    "s = m.addMVar(solarcnum, lb=0,ub=1, vtype=GRB.BINARY, name=solarnames) #indicator var for if site is built\n",
    "w = m.addMVar(windcnum, lb=0,ub=1, vtype=GRB.BINARY, name=windnames)\n",
    "slack = m.addMVar(h, lb=0, ub=slackcap, vtype=GRB.CONTINUOUS, name=slacknames)\n",
    "\n",
    "#for continuous model - upper_bound for solar/wind is max capacity for each fuel type in June 2020 GIS report\n",
    "#s = m.addMVar(solarcnum, lb=0,ub=610, vtype=GRB.CONTINUOUS, name=solarnames)\n",
    "#w = m.addMVar(windcnum, lb=0,ub=630, vtype=GRB.CONTINUOUS, name=windnames)\n",
    "\n",
    "#objective\n",
    "m.setObjective((solarcost @ s) + (windcost @ w), GRB.MINIMIZE)\n",
    "\n",
    "#constraints\n",
    "for hour in range(h):\n",
    "    m.addConstr((solarpower[hour,:] @ s) + (windpower[hour,:] @ w) >= coalhours[hour] - slack[hour])\n",
    "m.addConstr(sum(slack) <= 0.1*coaltotal) #allow % of total coal demand to be slacked\n",
    "\n",
    "\n",
    "#optimizing\n",
    "m.Params.MIPGap = 10**(-6)\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTERROGATING MODEL RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b49c8f10902b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msmallsites\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetVars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvarName\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'm' is not defined"
     ]
    }
   ],
   "source": [
    "#investigating model and reporting results\n",
    "#h = len(coalhours)\n",
    "slackedhours = 0 #how many hours did we not meet (significantly i.e. more than 1% off)\n",
    "slacksum = 0 #how much total load did we not meet\n",
    "powersum = 0\n",
    "slackout = []\n",
    "solarout = []\n",
    "windout = []\n",
    "smallsites = 0\n",
    "\n",
    "for v in m.getVars():\n",
    "    if v.x > 0.01:\n",
    "        name = v.varName\n",
    "        if 'Wind' in name:\n",
    "            windout.append(name)\n",
    "            if v.x < 1:\n",
    "                smallsites += 1\n",
    "            \n",
    "        elif 'Solar' in name:\n",
    "            solarout.append(name)\n",
    "            if v.x < 1:\n",
    "                smallsites += 1\n",
    "        elif 'Slack' in name:\n",
    "            slackedhours += 1\n",
    "            slacksum += v.x\n",
    "            [nada,hour] = name.split(':')\n",
    "            slackout.append(int(hour))\n",
    "        else:\n",
    "            powersum += v.x\n",
    "\n",
    "sint = [round(val) for val in s.x] \n",
    "wint = [round(val) for val in w.x]\n",
    "sitecost = np.matmul(solarcost,sint) + np.matmul(windcost,wint)\n",
    "#coaltotalcost = sum(slack.x)*coalcost\n",
    "solarpowerout = np.matmul(solarpower,sint)\n",
    "windpowerout = np.matmul(windpower,wint)\n",
    "powerout = solarpowerout + windpowerout\n",
    "    \n",
    "print('Solar sites used: %g' % len(solarout))\n",
    "print('Wind sites used: %g' % len(windout))\n",
    "print('Percent of Hours slacked: %g' % (slackedhours/h))\n",
    "print('Percent of Load slacked: %g' % (slacksum / coaltotal))\n",
    "print('Build Cost (Billion) %g' % (sitecost / 10**9))\n",
    "\n",
    "#saving site output\n",
    "#pd.DataFrame(data={'Solar': solarpowerout, 'Wind': windpowerout}).to_csv('ModelOut/Power90.csv')\n",
    "\n",
    "#saving solver info\n",
    "#m.write('out.mst')\n",
    "#m.write('out.attr')\n",
    "#m.write('out.mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving model chosen sites info - Figure 9\n",
    "solarmodel = defaultdict(float)\n",
    "windmodel = defaultdict(float)\n",
    "for site in solarout:\n",
    "    [county,cap] = site.split(' Solar: ')\n",
    "    solarmodel[county] += float(cap)\n",
    "for site in windout:\n",
    "    [county,cap] = site.split(' Wind: ')\n",
    "    windmodel[county] += float(cap)\n",
    "\n",
    "#combined all these sheets into Sites90.xlsx spreadsheet after running this cell\n",
    "pd.DataFrame(data=solarmodel,index=['Capacities']).to_csv('ModelOut/SolarOutSites.csv')\n",
    "pd.DataFrame(data=windmodel,index=['Capacities']).to_csv('ModelOut/WindOutSites.csv')\n",
    "pd.DataFrame(data={'Sites': solarout}).to_csv('ModelOut/SitesS.csv')\n",
    "pd.DataFrame(data={'Sites': windout}).to_csv('ModelOut/SitesW.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TABLE 4 - Testing generalizability to other years (only use this if doing train/test split)\n",
    "powertest = np.matmul(solarpowertest,sint) + np.matmul(windpowertest,wint)\n",
    "slacktest = 0 \n",
    "hourtest = 0\n",
    "dif = np.transpose(coalhours[0:17520]) - powertest\n",
    "\n",
    "for i in range(17520):\n",
    "    if dif[i] > 0:\n",
    "        slacktest += dif[i]\n",
    "        hourtest += 1\n",
    "print(1-(slacktest / (coaltotal/2)))\n",
    "print(1-(hourtest / 17520))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution - NOT USED\n",
    "coalcap = 14225\n",
    "#coal = pd.read_csv('Coal2019.csv',usecols=['Coal']).to_numpy().flatten()\n",
    "#coal = np.flip(np.sort(2*coal))\n",
    "#coalcf = coal / coalcap\n",
    "\n",
    "pdat = pd.read_csv('ModelOut/Power90.csv')\n",
    "solarp = 2*pdat['Solar'].to_numpy()\n",
    "windp = 2*pdat['Wind'].to_numpy()\n",
    "power = solarp + windp\n",
    "\n",
    "# y = 17520\n",
    "# syear1 = solarp[0:y]\n",
    "# syear2 = solarp[y:2*y]\n",
    "# syear3 = solarp[2*y:3*y]\n",
    "# wyear1 = windp[0:y]\n",
    "# wyear2 = windp[y:2*y]\n",
    "# wyear3 = windp[2*y:3*y]\n",
    "# ayear1 = power[0:y]\n",
    "# ayear2 = power[y:2*y]\n",
    "# ayear3 = power[2*y:3*y]\n",
    "\n",
    "solarcap = 11706.08\n",
    "windcap = 16611.35\n",
    "totalcap = solarcap + windcap\n",
    "\n",
    "# spd1 = np.flip(np.sort(syear1 / spoweravg))\n",
    "# spd2 = np.flip(np.sort(syear2 / spoweravg))\n",
    "# spd3 = np.flip(np.sort(syear3 / spoweravg))\n",
    "# wpd1 = np.flip(np.sort(wyear1 / wpoweravg))\n",
    "# wpd2 = np.flip(np.sort(wyear2 / wpoweravg))\n",
    "# wpd3 = np.flip(np.sort(wyear3 / wpoweravg))\n",
    "# apd1 = np.flip(np.sort(ayear1 / apoweravg))\n",
    "# apd2 = np.flip(np.sort(ayear2 / apoweravg))\n",
    "# apd3 = np.flip(np.sort(ayear3 / apoweravg))\n",
    "\n",
    "solarp = np.flip(np.sort(solarp / solarcap))\n",
    "windp = np.flip(np.sort(windp / windcap))\n",
    "power = np.flip(np.sort(power / totalcap))\n",
    "\n",
    "#yeardic = {'Solar 2009': spd1, 'Solar 2010': spd2, 'Solar 2011': spd3, 'Wind 2009': wpd1, 'Wind 2010': wpd2, 'Wind 2011': wpd3, 'Both 2009': apd1, 'Both 2010': apd2, 'Both 2011': apd3}\n",
    "alldic = {'Solar': solarp, 'Wind': windp, 'Both': power}\n",
    "\n",
    "#pd.DataFrame(data={'Coal Dist': coalyear}).to_csv('CoalDistrYear.csv')\n",
    "#pd.DataFrame(data={'Coal Dist': coalall}).to_csv('CoalDistrExtended.csv')\n",
    "#pd.DataFrame(data=yeardic).to_csv('ModelDistrYears.csv')\n",
    "pd.DataFrame(data=alldic).to_csv('ModelDistr.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monthly average Capacity Factor graph for each fuel type - NOT USED\n",
    "\n",
    "solarpoweragg = np.sum(solarpower,axis=1) #/ 213 #213 counties\n",
    "windpoweragg = np.sum(windpower,axis=1) #/ 213\n",
    "\n",
    "coal = 'Coal2019.csv'\n",
    "coalhours = pd.read_csv(coal,usecols=['Coal']).to_numpy()\n",
    "\n",
    "solaryear = np.empty(17520)\n",
    "windyear = np.empty(17520)\n",
    "for i in range(17520):\n",
    "    solaryear[i] = sum(solarpoweragg[i::17520])/3\n",
    "    windyear[i] = sum(windpoweragg[i::17520])/3\n",
    "\n",
    "solaryear = 2*solaryear / sum(solarcaps)\n",
    "windyear = 2*windyear / sum(windcaps)\n",
    "coalhours = 2*coalhours / 15065\n",
    "days = [31,28,31,30,31,30,31,31,30,31,30,31]\n",
    "d=0\n",
    "\n",
    "sma = np.empty(12); wma = np.empty(12); cma = np.empty(12);\n",
    "for month in range(12):\n",
    "        sma[month] = sum(solaryear[(d*48):((d+days[month])*48)]) / (days[month]*48)\n",
    "        wma[month] = sum(windyear[(d*48):((d+days[month])*48)]) / (days[month]*48)\n",
    "        cma[month] = sum(coalhours[(d*48):((d+days[month])*48)]) / (days[month]*48) #coal max = 6950\n",
    "        d += days[month]\n",
    "        \n",
    "# pd.DataFrame(data=sma).to_csv('SolarMonthlyCF.csv')\n",
    "# pd.DataFrame(data=wma).to_csv('WindMonthlyCF.csv')\n",
    "# pd.DataFrame(data=cma).to_csv('CoalMonthlyCF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadzones = ['HB_NORTH', 'HB_SOUTH', 'HB_WEST']\n",
    "weathertoload = {'NORTH': 'HB_WEST', 'NCENT': 'HB_NORTH', 'EAST': 'HB_NORTH', 'COAST': 'HB_SOUTH', 'SOUTH': 'HB_SOUTH', 'SCENT': 'HB_SOUTH', 'WEST': 'HB_WEST', 'FWEST': 'HB_WEST'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting regional info\n",
    "y = 17520\n",
    "n = 3*y\n",
    "solarregout = dict.fromkeys(regions,np.zeros(y)) #every half-hour\n",
    "solarregcap = dict.fromkeys(regions,0)\n",
    "windregout = dict.fromkeys(regions,np.zeros(y))\n",
    "windregcap = dict.fromkeys(regions,0)\n",
    "\n",
    "#if you want to analyze only 90% model sites use this\n",
    "pdat = pd.read_excel('Sites90.xlsx',sheet_name='SitesLong')\n",
    "solarout = pdat['Solar'].dropna().to_list()\n",
    "windout = pdat['Wind'].dropna().to_list()\n",
    "\n",
    "#to compare regional load to power\n",
    "# solarloadout = dict.fromkeys(loadzones,np.zeros(y))\n",
    "# windloadout = dict.fromkeys(loadzones,np.zeros(y))\n",
    "\n",
    "#to look at revenue,cost,profit\n",
    "solarprofit = np.zeros(262)\n",
    "windprofit = np.zeros(108)\n",
    "\n",
    "for site in solarout:\n",
    "    i = solarnames.index(site)\n",
    "    sitepower = solarpower[:,i]\n",
    "    cap = solarcaps[i]\n",
    "    county = solarcounts[i]\n",
    "    reg = simpregdict[county][0]\n",
    "    avpower = (sitepower[0:y] + sitepower[y:(2*y)] + sitepower[(2*y):(3*y)])/3\n",
    "    solarregout[reg] = solarregout[reg] + avpower #((sitepower[::2] + sitepower[1::2]) / 1) #divide by 2 b/c want avg power (if MWh don't)\n",
    "    solarregcap[reg] = solarregcap[reg] + cap\n",
    "    \n",
    "    #if you want to compare regional load to power\n",
    "#     avpower = (sitepower[0:y] + sitepower[y:(2*y)] + sitepower[(2*y):(3*y)])/3\n",
    "#     cost = solarcost[i]\n",
    "#     loadreg = weathertoload[reg]\n",
    "#     solarloadout[loadreg] = solarloadout[loadreg] + avpower\n",
    "    #if you want to look at revenue,cost,profit\n",
    "#     rev = np.matmul(energyprice[loadreg],avpower)\n",
    "#     solarprofit[i] = (rev - cost) #annual\n",
    "    \n",
    "for site in windout:\n",
    "    i = windnames.index(site)\n",
    "    sitepower = windpower[:,i]\n",
    "    cap = windcaps[i]\n",
    "    county = windcounts[i]\n",
    "    reg = simpregdict[county][0]\n",
    "    avpower = (sitepower[0:y] + sitepower[y:(2*y)] + sitepower[(2*y):(3*y)])/3\n",
    "    windregout[reg] = windregout[reg] + avpower\n",
    "    windregcap[reg] = windregcap[reg] + cap\n",
    "    \n",
    "    #if you want to compare regional load to power\n",
    "#     avpower = (sitepower[0:y] + sitepower[y:(2*y)] + sitepower[(2*y):(3*y)])/3\n",
    "#     cost = windcost[i]\n",
    "#     loadreg = weathertoload[reg]\n",
    "#     windloadout[loadreg] = windloadout[loadreg] + avpower\n",
    "    #if you want to look at revenue,cost,profit\n",
    "#     rev = np.matmul(energyprice[loadreg],avpower)\n",
    "#     windprofit[i] = (rev - cost) #annual\n",
    "    \n",
    "solarregcf = {}\n",
    "windregcf = {}\n",
    "regcap = {}\n",
    "for reg in regions:\n",
    "    solarregcf[reg] = 2*solarregout[reg] / solarregcap[reg]\n",
    "    windregcf[reg] = 2*windregout[reg] / windregcap[reg]\n",
    "    regcap[reg] = [solarregcap[reg],windregcap[reg]]    \n",
    "#pd.DataFrame(data=regcap).to_csv('RegOut.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#which sites are the most efficient (cost per MW), what range of costs do we have (Figure 10)\n",
    "coaltotal = sum(coalhours)\n",
    "coalgwh = coaltotal / (3*10**3)\n",
    "pdat = pd.read_excel('Sites90.xlsx',sheet_name='SitesLong')\n",
    "solarout = pdat['Solar'].dropna().to_list()\n",
    "windout = pdat['Wind'].dropna().to_list()\n",
    "sitesout = pdat['Solar'].dropna().to_list() + pdat['Wind'].to_list()\n",
    "\n",
    "#2.81 billion\n",
    "\n",
    "ssum = sum(solarpower) / 3\n",
    "wsum = sum(windpower) / 3\n",
    "seff = solarcost / ssum\n",
    "weff = windcost / wsum\n",
    "#seff = solarprofit / (10**6)\n",
    "#weff = windprofit / (10**6)\n",
    "twine = []\n",
    "\n",
    "for i in range(windcnum):\n",
    "    #twine.append((seff[i],ssum[i],solarnames[i]))\n",
    "    #twine.append((weff[i],wsum[i],windnames[i]))\n",
    "    twine.append((seff[i],solarcost[i],i,solarnames[i], ssum[i]))\n",
    "    twine.append((weff[i],windcost[i],i,windnames[i], wsum[i]))\n",
    "for i in range(windcnum,solarcnum):\n",
    "    #twine.append((seff[i],ssum[i],solarnames[i]))\n",
    "    twine.append((seff[i],solarcost[i],i,solarnames[i], ssum[i]))\n",
    "\n",
    "twine.sort()\n",
    "#twine.reverse() #need to reverse for falling profitability\n",
    "order = []\n",
    "efforder = []\n",
    "sumorder = []\n",
    "\n",
    "fcolor = []\n",
    "totalcost = 0\n",
    "powerpack = np.zeros(52560)\n",
    "for i in range(windcnum+solarcnum):\n",
    "    name = twine[i][3]\n",
    "    idx = twine[i][2]\n",
    "    cost = twine[i][1]\n",
    "    order.append(name)\n",
    "    efforder.append(twine[i][0])\n",
    "    sumorder.append(twine[i][4] / 10**3)\n",
    "    if 'Solar:' in name:\n",
    "        fcolor.append('bisque')\n",
    "        powerpack += solarpower[:,idx]\n",
    "    else:\n",
    "        fcolor.append('lightsteelblue')\n",
    "        powerpack += windpower[:,idx]\n",
    "\n",
    "        \n",
    "for site in sitesout:\n",
    "    i = order.index(site)\n",
    "    if fcolor[i] == 'bisque':\n",
    "        fcolor[i] = 'darkorange'\n",
    "    elif fcolor[i] == 'lightsteelblue':\n",
    "        fcolor[i] = 'blue'\n",
    "\n",
    "sp = 0; sc = 0;\n",
    "wp = 0; wc = 0;\n",
    "\n",
    "for site in solarout:\n",
    "    i = solarnames.index(site)\n",
    "    sp += ssum[i]\n",
    "    sc += solarcost[i]\n",
    "for site in windout:\n",
    "    i = windnames.index(site)\n",
    "    wp += wsum[i]\n",
    "    wc += windcost[i]\n",
    "#print(sp,sc,wp,wc)\n",
    "print((sc+wc) / (sp+wp))\n",
    "\n",
    "# popi = []        \n",
    "# for i in range(0,len(sitesout)-1):\n",
    "#     n = i+1\n",
    "#     count = order[i].split(':')[0]\n",
    "#     sc = sumorder[i]\n",
    "#     while count == order[n].split(':')[0]:\n",
    "#         sc += sumorder[n]\n",
    "#         popi.append(n)\n",
    "#         n = n+1\n",
    "#     sumorder[i] = sc\n",
    "        \n",
    "# for i in popi:\n",
    "#     order.pop(i); efforder.pop(i); sumorder.pop(i); fcolor.pop(i);\n",
    "\n",
    "xs = np.zeros(solarcnum+windcnum)\n",
    "for i in range(1,solarcnum+windcnum):\n",
    "    xs[i] = xs[i-1] + sumorder[i-1]\n",
    "    if abs(efforder[i]) < 0.2:\n",
    "        efforder[i] += (efforder[i] / (2*abs(efforder[i])))\n",
    "        print(order[i],efforder[i])\n",
    "\n",
    "srange = [min(seff),max(seff)]\n",
    "wrange = [min(weff),max(weff)]\n",
    "print('Solar Price Per MWh Range: %s' % srange)\n",
    "print('Wind Price Per MWh Range: %s' % wrange)\n",
    "\n",
    "# for i in range(windcnum):\n",
    "#     sorder.append(stwine[i][1])\n",
    "#     worder.append(wtwine[i][1])\n",
    "# for i in range(windcnum,solarcnum):\n",
    "#     sorder.append(stwine[i][1])\n",
    "\n",
    "# sorder = list(dict.fromkeys(sorder)) #remove repeats\n",
    "# worder = list(dict.fromkeys(worder))\n",
    "# sorder = [count + ' Solar' for count in sorder]\n",
    "# worder = [count + ' Wind' for count in worder]\n",
    "\n",
    "#basically want to see whether its taking greedy 'best' sites or not\n",
    "# sg = defaultdict(float)\n",
    "# wg = defaultdict(float)\n",
    "\n",
    "\n",
    "# for count in solarout:\n",
    "#     [x,y] = count.split(':')\n",
    "#     i = sorder.index(x)\n",
    "#     sg[i+1] += float(y)\n",
    "# for count in windout:\n",
    "#     [x,y] = count.split(':')\n",
    "#     i = worder.index(x)\n",
    "#     wg[i+1] += float(y)\n",
    "\n",
    "# sg = dict(sorted(sg.items()))\n",
    "# wg = dict(sorted(wg.items()))\n",
    "\n",
    "# pd.DataFrame(data=[sg,wg]).to_csv('Eff90Full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure 10 - efficiency of used and left out sites\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator, FuncFormatter\n",
    "import math\n",
    "\n",
    "fig,ax = plt.subplots(1, figsize=(10,5))\n",
    "#plt.grid(zorder=0); ax.set_axisbelow(True)\n",
    "plt.bar(x=xs, height=efforder, width=sumorder, align='edge', color=fcolor)\n",
    "plt.axvline(x=coalgwh,linestyle='--',color='black'); plt.text(coalgwh+1000,40,'Coal GWh')\n",
    "plt.xlabel('Annual Energy Supplied (GWh)'); plt.ylabel('Levelized Cost ($ / MWh)');\n",
    "ax.set_xlim((0,xs[-1]+5000)); \n",
    "ax.xaxis.set_major_locator(MultipleLocator(25000)); \n",
    "#ax.xaxis.set_minor_locator(MultipleLocator(25000))\n",
    "ax.get_xaxis().set_major_formatter(FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(5))\n",
    "ax.spines['bottom'].set_color('gray'); ax.spines['top'].set_color('white');\n",
    "ax.spines['right'].set_color('white'); ax.spines['left'].set_color('gray');\n",
    "\n",
    "lcolors = {'Wind: Selected':'blue', 'Wind: Unselected':'lightsteelblue','Solar: Selected':'darkorange', 'Solar: Unselected':'bisque'}   \n",
    "lecolors = {'Wind: Selected':'blue', 'Wind: Unselected':'lightsteelblue','Solar: Selected':'darkorange', 'Solar: Unselected':'bisque'} \n",
    "labels = list(lcolors.keys())\n",
    "handles = [plt.Rectangle((0,0),1,1, facecolor=lcolors[label], edgecolor=lecolors[label]) for label in labels]\n",
    "#plt.legend(handles, labels)\n",
    "ax.legend(handles, labels, bbox_to_anchor=(0.21, 1.05))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('Site_Selection_Bar_MarginalCost', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fuel mix info (Figure 11)\n",
    "\n",
    "#fuel = 'Fuel2011.xls' \n",
    "#months = ['Jan11','Feb11','Mar11','Apr11','May11','Jun11','Jul11','Aug11','Sep11','Oct11','Nov11','Dec11']\n",
    "fuel = 'Fuel2019.xlsx'\n",
    "months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "xls = pd.ExcelFile(fuel)\n",
    "\n",
    "biomass = np.empty(0)\n",
    "coal = np.empty(0)\n",
    "gas = np.empty(0)\n",
    "gascc = np.empty(0)\n",
    "hydro = np.empty(0)\n",
    "nuclear = np.empty(0)\n",
    "other = np.empty(0)\n",
    "solar = np.empty(0)\n",
    "wind = np.empty(0)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(12):\n",
    "    dat = pd.read_excel(xls, months[i])\n",
    "    \n",
    "    biomassyear = dat.loc[dat['Fuel']==\"Biomass\"]\n",
    "    biomassyear = biomassyear[biomassyear.columns[4::2]].to_numpy() + biomassyear[biomassyear.columns[5::2]].to_numpy()\n",
    "    biomassyear = np.reshape(biomassyear,np.prod(biomassyear.shape))\n",
    "    biomass = np.concatenate((biomass,biomassyear))\n",
    "    \n",
    "    coalyear = dat.loc[dat['Fuel']==\"Coal\"]\n",
    "    coalyear = coalyear[coalyear.columns[4::2]].to_numpy() + coalyear[coalyear.columns[5::2]].to_numpy()\n",
    "    coalyear = np.reshape(coalyear,np.prod(coalyear.shape))\n",
    "    coal = np.concatenate((coal,coalyear))\n",
    "    \n",
    "    gasyear = dat.loc[dat['Fuel']==\"Gas\"]\n",
    "    gasyear = gasyear[gasyear.columns[4::2]].to_numpy() + gasyear[gasyear.columns[5::2]].to_numpy()\n",
    "    gasyear = np.reshape(gasyear,np.prod(gasyear.shape))\n",
    "    gas = np.concatenate((gas,gasyear))\n",
    "\n",
    "    gasccyear = dat.loc[dat['Fuel']==\"Gas-CC\"]\n",
    "    gasccyear = gasccyear[gasccyear.columns[4::2]].to_numpy() + gasccyear[gasccyear.columns[5::2]].to_numpy()\n",
    "    gasccyear = np.reshape(gasccyear,np.prod(gasccyear.shape))\n",
    "    gascc = np.concatenate((gascc,gasccyear))\n",
    "\n",
    "    hydroyear = dat.loc[dat['Fuel']==\"Hydro\"]\n",
    "    hydroyear = hydroyear[hydroyear.columns[4::2]].to_numpy() + hydroyear[hydroyear.columns[5::2]].to_numpy()\n",
    "    hydroyear = np.reshape(hydroyear,np.prod(hydroyear.shape))\n",
    "    hydro = np.concatenate((hydro,hydroyear))\n",
    "    \n",
    "    nuclearyear = dat.loc[dat['Fuel']==\"Nuclear\"]\n",
    "    nuclearyear = nuclearyear[nuclearyear.columns[4::2]].to_numpy() + nuclearyear[nuclearyear.columns[5::2]].to_numpy()\n",
    "    nuclearyear = np.reshape(nuclearyear,np.prod(nuclearyear.shape))\n",
    "    nuclear = np.concatenate((nuclear,nuclearyear))\n",
    "    \n",
    "    otheryear = dat.loc[dat['Fuel']==\"Other\"]\n",
    "    otheryear = otheryear[otheryear.columns[4::2]].to_numpy() + otheryear[otheryear.columns[5::2]].to_numpy()\n",
    "    otheryear = np.reshape(otheryear,np.prod(otheryear.shape))\n",
    "    other = np.concatenate((other,otheryear))\n",
    "\n",
    "    solaryear = dat.loc[dat['Fuel']==\"Solar\"]\n",
    "    solaryear = solaryear[solaryear.columns[4::2]].to_numpy() + solaryear[solaryear.columns[5::2]].to_numpy()\n",
    "    solaryear = np.reshape(solaryear,np.prod(solaryear.shape))\n",
    "    solar = np.concatenate((solar,solaryear))\n",
    "\n",
    "    windyear = dat.loc[dat['Fuel']==\"Wind\"]\n",
    "    windyear = windyear[windyear.columns[4::2]].to_numpy() + windyear[windyear.columns[5::2]].to_numpy()\n",
    "    windyear = np.reshape(windyear,np.prod(windyear.shape))\n",
    "    wind = np.concatenate((wind,windyear))\n",
    "    \n",
    "biomass = np.nan_to_num(biomass)\n",
    "coal = np.nan_to_num(coal) # / (18774/2) # (14297/2)\n",
    "gas = np.nan_to_num(gas) # / (47259/2)\n",
    "gascc = np.nan_to_num(gascc)\n",
    "hydro = np.nan_to_num(hydro)\n",
    "nuclear = np.nan_to_num(nuclear)\n",
    "other = np.nan_to_num(other)\n",
    "solar = np.nan_to_num(solar)\n",
    "wind = np.nan_to_num(wind) # / (9452/2)\n",
    "solar = np.nan_to_num(solar)\n",
    "#solar = pd.read_excel('SolarProfile2011.xlsx',usecols=['Total']).to_numpy().flatten()\n",
    "#solar = solar / max(solar)\n",
    "#oldrenewables = wind+other+hydro\n",
    "#total = coal+gas+nuclear+oldrenewables\n",
    "oldrenewables = solar+wind+other+biomass+hydro\n",
    "total = coal+gas+gascc+nuclear+oldrenewables\n",
    "total3 = np.hstack((total,total,total))\n",
    "\n",
    "pdat = pd.read_csv('Power90.csv')\n",
    "solarp = pdat['Solar'].to_numpy()\n",
    "windp = pdat['Wind'].to_numpy()\n",
    "'''\n",
    "solarpower = np.empty(17520)\n",
    "windpower = np.empty(17520)\n",
    "for i in range(17520):\n",
    "    solarpower[i] = sum(solarp[i::17520])/3\n",
    "    windpower[i] = sum(windp[i::17520])/3\n",
    "    \n",
    "pdat = pd.read_excel('Sites90.xlsx',sheet_name='SitesLong')\n",
    "solarout = pdat['Solar'].dropna().to_list()\n",
    "windout = pdat['Wind'].dropna().to_list()\n",
    "sitesout = pdat['Solar'].dropna().to_list() + pdat['Wind'].to_list()\n",
    "\n",
    "solarmodel = np.zeros(52560)\n",
    "windmodel = np.zeros(52560)\n",
    "sc = 0; wc = 0;\n",
    "\n",
    "for site in solarout:\n",
    "    i = solarnames.index(site)\n",
    "    solarmodel += solarpower[:,i]\n",
    "    cap = float(site.split(': ')[1])\n",
    "    sc += cap\n",
    "for site in windout:\n",
    "    i = windnames.index(site)\n",
    "    windmodel += windpower[:,i]\n",
    "    cap = float(site.split(': ')[1])\n",
    "    wc += cap\n",
    "\n",
    "totalmodel = 2*(solarmodel + windmodel) / (sc+wc)\n",
    "solarmodel = 2*solarmodel / sc\n",
    "windmodel = 2*windmodel / wc\n",
    "\n",
    "gas3 = 2*(gas + gascc) / (19310 + 35564)\n",
    "gas3 = np.hstack((gas3,gas3,gas3))\n",
    "\n",
    "solarmodelh = (solarmodel[::2] + solarmodel[1::2]) / 2\n",
    "windmodelh = (windmodel[::2] + windmodel[1::2]) / 2\n",
    "windh = (wind[::2] + wind[1::2]) / 2\n",
    "coalh = (coal[::2] + coal[1::2]) / 2\n",
    "gash = (gas[::2] + gas[1::2]) / 2\n",
    "print(coalh.shape)\n",
    "'''\n",
    "\n",
    "load2009 = pd.read_excel('ERCOT/Load/2009_ERCOT_Hourly_Load_Data.xls',usecols=['ERCOT']).to_numpy().flatten()\n",
    "load2009 = np.repeat(load2009, 2)\n",
    "load2010 = pd.read_excel('ERCOT/Load/2010_ERCOT_Hourly_Load_Data.xls',usecols=['ERCOT']).to_numpy().flatten()\n",
    "load2010 = np.repeat(load2010, 2)\n",
    "load2011 = pd.read_excel('ERCOT/Load/Native_Load_2011.xls',usecols=['ERCOT']).to_numpy().flatten()\n",
    "load2011 = np.repeat(load2011, 2)\n",
    "load = pd.read_excel('ERCOT/Load/Native_Load_2019.xlsx',usecols=['ERCOT']).to_numpy().flatten()\n",
    "load2019 = np.repeat(load, 2)\n",
    "\n",
    "y = 17520\n",
    "gas2019 = gas + gascc\n",
    "coal2019 = coal\n",
    "outdic = {'Load 2009': load2009,'Load 2010': load2010,'Load 2011': load2011, 'Load 2019': load2019, 'Solar 2009': 2*solarp[0:y],\n",
    "          'Solar 2010': 2*solarp[y:(2*y)], 'Solar 2011': 2*solarp[(2*y):(3*y)], 'Wind 2009': 2*windp[0:y],\n",
    "          'Wind 2010': 2*windp[y:(2*y)], 'Wind 2011': 2*windp[(2*y):(3*y)], 'Coal 2019': 2*coal2019, 'Gas 2019': 2*gas2019}\n",
    "# pd.DataFrame(data = outdic).to_csv('Output_vs_Load.csv')\n",
    "\n",
    "\n",
    "\n",
    "load3 = np.hstack((load,load,load))\n",
    "\n",
    "#oldrenewablesh = oldrenewables[::2] + oldrenewables[1::2]\n",
    "coalh = coal[::2] + coal[1::2]\n",
    "solarph = solarp[::2] + solarp[1::2]\n",
    "windph = windp[::2] + windp[1::2]\n",
    "\n",
    "#oldrenew3 = np.hstack((oldrenewablesh,oldrenewablesh,oldrenewablesh))\n",
    "coalh3 = np.hstack((coalh,coalh,coalh))\n",
    "coal3 = np.hstack((coal,coal,coal))\n",
    "old = load3 - coalh3\n",
    "new = load3 - (solarph+windph)\n",
    "\n",
    "\n",
    "allgas = gas + gascc\n",
    "gas3 = np.hstack((allgas,allgas,allgas))\n",
    "dif = coal3 - (solarp+windp)\n",
    "newgas = gas3+dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure 11 - fuel mix graph\n",
    "bh = np.empty(48); ch = np.empty(48); gh = np.empty(48); gcch = np.empty(48); hh = np.empty(48); nh = np.empty(48);\n",
    "oh = np.empty(48); sh = np.empty(48); wh = np.empty(48); sph = np.empty(48); wph = np.empty(48);\n",
    "\n",
    "mi = 8688 #0 #0\n",
    "mf = 10176 #1488 #17520\n",
    "dn = 31 #31 #365 \n",
    "\n",
    "for h in range(48):\n",
    "    bh[h] = (2*sum(biomass[mi+h:mf:48])) / dn\n",
    "    ch[h] = (2*sum(coal[mi+h:mf:48])) / dn\n",
    "    gh[h] = (2*sum(gas[mi+h:mf:48])) / dn\n",
    "    gcch[h] = (2*sum(gascc[mi+h:mf:48])) / dn\n",
    "    hh[h] = (2*sum(hydro[mi+h:mf:48])) / dn\n",
    "    nh[h] = (2*sum(nuclear[mi+h:mf:48])) / dn\n",
    "    oh[h] = (2*sum(other[mi+h:mf:48])) / dn\n",
    "    sh[h] = (2*sum(solar[mi+h:mf:48])) / dn\n",
    "    wh[h] = (2*sum(wind[mi+h:mf:48])) / dn\n",
    "    sph[h] = (2*sum(solarpower[mi+h:mf:48])) / dn\n",
    "    wph[h] = (2*sum(windpower[mi+h:mf:48])) / dn\n",
    "    \n",
    "#formatting to make that graph I want (basically need to put things on top of one another)\n",
    "total = nh+hh+bh+oh+sh+wh+gh+gcch+ch\n",
    "    \n",
    "outdic = {'Nuclear':nh, 'Hydrothermal/Biomass/Other':hh+bh+oh, 'Solar':sh, 'New Solar':sph, 'Wind':wh, 'New Wind':wph, 'Gas-CC':gcch, 'Gas':gh, 'Coal':ch, 'Total ERCOT Generation':total}\n",
    "\n",
    "pd.DataFrame(data=outdic).to_excel('FuelHoursJul.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure 12 - Required Ramping of other energy sources to satisfy load (based off fuel mix and model data)\n",
    "yh = 8760\n",
    "oldavg = sum(old) / (yh*3)\n",
    "newavg = sum(new)/ (yh*3)\n",
    "oldpeak = max(old)\n",
    "newpeak = max(new)\n",
    "oldstd = np.std(old)\n",
    "newstd = np.std(new)\n",
    "print(oldpeak/oldavg,oldstd,newpeak/newavg,newstd)\n",
    "\n",
    "#monthly comparison of old and new required ramping\n",
    "#can easily be done for full year if mi = 0, mf = yh, and days[month] is set to 365\n",
    "outday = {}\n",
    "for month in range(12):\n",
    "    oldday = np.empty(24)\n",
    "    newday = np.empty(24)\n",
    "    mi = hsums[month] // 2 #divide by 2 because half-hours, no rounding errors in division (all will be integers)\n",
    "    mf = hsums[month+1] // 2\n",
    "    for h in range(24):\n",
    "        oldday[h] = sum(old[mi+h:mf:24] + old[mi+h+yh:mf+yh:24] + old[mi+h+(2*yh):mf+(2*yh):24]) / (days[month]*3)\n",
    "        newday[h] = sum(new[mi+h:mf:24] + new[mi+h+yh:mf+yh:24] + new[mi+h+(2*yh):mf+(2*yh):24]) / (days[month]*3)\n",
    "        outday['Old' + months[month]] = oldday\n",
    "        outday['New' + months[month]] = newday\n",
    "\n",
    "#top level analysis\n",
    "olddist = np.flip(np.sort(old / oldavg))\n",
    "newdist = np.flip(np.sort(new / newavg))\n",
    "outlong = {'Old Req':old, 'New Req': new}\n",
    "outdist = {'Old Req Dist':olddist, 'New Req Dist': newdist}\n",
    "\n",
    "#pd.DataFrame(data=outlong).to_excel('RequiredRamping.xlsx')\n",
    "pd.DataFrame(data=outday).to_excel('RequiredRamping.xlsx')\n",
    "\n",
    "#plt.plot(new, color='blue')\n",
    "#plt.plot(old, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model info and analysis of slack\n",
    "surh = dif < 0\n",
    "surplus = abs(dif[surh])\n",
    "slkh = dif > 0\n",
    "slack = dif[slkh]\n",
    "old1 = sum(surh)\n",
    "old2 = sum(surplus)\n",
    "old3 = sum(slkh)\n",
    "old4 = sum(slack)\n",
    "\n",
    "surlh = newgas < 0\n",
    "surloss = abs(newgas[surlh]) / 2\n",
    "slklh = newgas > gc3\n",
    "slackloss = newgas - gc3; slackloss = slackloss[slklh] / 2\n",
    "new1 = sum(surlh)\n",
    "new2 = sum(surloss)\n",
    "new3 = sum(slklh)\n",
    "new4 = sum(slackloss)\n",
    "print(old2,old4,new2,new4)\n",
    "print(new1/old1,new2/old2,new3/old3,new4/old4)\n",
    "print(new3 / 52560, new4 / sum(coal3))\n",
    "print(new4 / new3)\n",
    "#1.9% of surplus will need to be curtailed (or replace other things), on 4.1% of all half-hours where the model produces a surplus\n",
    "#0.03% of coal production will be unable to be met by spare gas. These losses will occur on 0.1% of half-hours\n",
    "#the average loss will be 500 MWh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slack by Month\n",
    "slack = pd.read_csv('Slack90.csv',usecols=['Slack']).to_numpy().flatten()\n",
    "\n",
    "months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "daysog = [31,28,31,30,31,30,31,31,30,31,30,31]\n",
    "daysleap = [31,29,31,30,31,30,31,31,30,31,30,31]\n",
    "t = 17520\n",
    "yrhours = [t,t,t] #for leap this would be t + 48\n",
    "baseyear = 2009\n",
    "\n",
    "ms = np.zeros(12)\n",
    "cms = np.zeros(12)\n",
    "ys = np.zeros(3)\n",
    "\n",
    "for halfhour in range(len(slack)):\n",
    "    oghh = halfhour\n",
    "    yi = 0\n",
    "    while halfhour >= yrhours[yi]:\n",
    "        halfhour -= yrhours[yi]\n",
    "        yi += 1\n",
    "    \n",
    "    year = baseyear + yi\n",
    "    \n",
    "    if (year % 4) == 0:\n",
    "        days = daysleap\n",
    "    else:\n",
    "        days = daysog\n",
    "\n",
    "    day = (halfhour // 48) + 1\n",
    "    mi = 0\n",
    "    while day > days[mi]:\n",
    "        day -= days[mi]\n",
    "        mi += 1  \n",
    "    \n",
    "    month = months[mi]\n",
    "    hour = (halfhour % 48) / 2\n",
    "    ys[yi] += slack[oghh]\n",
    "    ms[mi] += slack[oghh]\n",
    "    \n",
    "for halfhour in range(t):\n",
    "    oghh = halfhour\n",
    "\n",
    "    days = daysog\n",
    "    day = (halfhour // 48) + 1\n",
    "    mi = 0\n",
    "    while day > days[mi]:\n",
    "        day -= days[mi]\n",
    "        mi += 1  \n",
    "    \n",
    "    month = months[mi]\n",
    "    cms[mi] += coalhours[oghh]\n",
    "\n",
    "# pd.DataFrame(data={'Slack':ms}).to_csv('SlackMonths.csv')   \n",
    "# pd.DataFrame(data={'Slack':ys}).to_csv('SlackYears.csv')\n",
    "# pd.DataFrame(data={'Coal':cms}).to_csv('CoalMonths.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure 13 - regional power sums of coal and model\n",
    "coalregs = pd.read_csv('CoalRegional2019.csv')\n",
    "regsums = {}\n",
    "totals = [0,0,0]\n",
    "for reg in regions:\n",
    "    regsums[reg] = [sum(solarregout[reg])/(3*1000),sum(windregout[reg])/(3*1000),sum(coalregs[reg])/1000]\n",
    "    totals[0] += sum(solarregout[reg])/(3*1000); totals[1] += sum(windregout[reg])/(3*1000)\n",
    "    totals[2] += sum(coalregs[reg])/1000\n",
    "revd = 0\n",
    "powerall = np.zeros(17520)\n",
    "for reg in loadzones:\n",
    "    regpower = solarloadout[reg]+windloadout[reg]\n",
    "    revd += np.matmul(energyprice[reg],regpower)\n",
    "    print(sum(regpower) / 1000)\n",
    "    powerall += regpower\n",
    "rev = np.matmul(energyprice['HB_HUBAVG'],powerall)\n",
    "revcoal = np.matmul(energyprice['HB_HUBAVG'],coalhours[0:17520])\n",
    "scale = 10**9\n",
    "print(sum(coalhours[0:17520]) / 1000)\n",
    "print(totals)\n",
    "#print(revd / scale, rev / scale, revcoal / scale)\n",
    "#print(regsums)\n",
    "pd.DataFrame(data=regsums).to_csv('RegSums.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quartiles - NOT USED\n",
    "csv = 'ModelOut/Power90.csv'\n",
    "pdat = pd.read_csv(csv)\n",
    "allpower = 2*(pdat['Solar'].to_numpy() + pdat['Wind'].to_numpy())\n",
    "print(allpower.shape)\n",
    "n = 17520\n",
    "\n",
    "year1 = allpower[0:n].flatten()\n",
    "year2 = allpower[n:(2*n)].flatten()\n",
    "year3 = allpower[(2*n):(3*n)].flatten()\n",
    "\n",
    "day1 = np.empty(48)\n",
    "day2 = np.empty(48)\n",
    "day3 = np.empty(48)\n",
    "jan1 = np.empty(48)\n",
    "jan2 = np.empty(48)\n",
    "jan3 = np.empty(48)\n",
    "jul1 = np.empty(48)\n",
    "jul2 = np.empty(48)\n",
    "jul3 = np.empty(48)\n",
    "#aprall = np.empty(48)\n",
    "#octall = np.empty(48)\n",
    "\n",
    "for i in range(48):\n",
    "    day = np.sort(allpower[i::48])   #(year1[i::48])\n",
    "    day1[i] = (day[273]) #1st quratile ie median of first half (day[90] + day[91])/2\n",
    "    day2[i] = day[547] #2nd quartile ie median (day[182])\n",
    "    day3[i] = day[821]# (day[273] + day[274]) / 2\n",
    "    jan = np.sort(np.hstack((year1[i:1488:48],year2[i:1488:48],year3[i:1488:48])))   #(year1[i:1488:48])\n",
    "    jan1[i] = (jan[22] + jan[23]) / 2 #jan[7]\n",
    "    jan2[i] = jan[46]#jan[15]\n",
    "    jan3[i] = (jan[69] + jan[70]) / 2 #jan[23]\n",
    "    jul = np.sort(np.hstack((year1[8688+i:10176:48],year2[8688+i:10176:48],year3[8688+i:10176:48])))   #(year1[8688+i:10176:48])\n",
    "    jul1[i] = (jul[22] + jul[23]) / 2 #jul[7]\n",
    "    jul2[i] = jul[46] #jul[15]\n",
    "    jul3[i] = (jul[69] + jul[70]) / 2 #jul[23]\n",
    "    #aprall[i] = (sum(year1[4320+i:5760:48]) + sum(year2[4320+i:5760:48]) + sum(year3[4320+i:5760:48])) / (3*30)\n",
    "    #octall[i] = (sum(year1[13104+i:14592:48]) + sum(year2[13104+i:14592:48]) + sum(year3[13104+i:14592:48])) / (3*31)\n",
    "\n",
    "#years = {'2009 Year': year1, '2010 Year': year2, '2011 Year': year3}\n",
    "#alld = {'2009 Day': day1, '2010 Day': day2, '2011 Day': day3}\n",
    "alld = {'Year Q1': day1, 'Year Q2': day2, 'Year Q3': day3}\n",
    "alld['Jan Q1'] = jan1\n",
    "alld['Jan Q2'] = jan2\n",
    "alld['Jan Q3'] = jan3\n",
    "alld['Jul Q1'] = jul1 \n",
    "alld['Jul Q2'] = jul2\n",
    "alld['Jul Q3'] = jul3\n",
    "#aproct = {'April': aprall, 'October': octall}\n",
    "\n",
    "#pd.DataFrame(data=alld).to_excel('Model90Qs.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

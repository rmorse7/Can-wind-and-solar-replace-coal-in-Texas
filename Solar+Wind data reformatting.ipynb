{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import os\n",
    "import reverse_geocoder as rg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "icd = 'SOLAR_PV_UTILITY_TEXAS.xlsx' #all 254 counties in TX\n",
    "\n",
    "non_ercot_counties = ['El Paso','Hudspeth','Gaines','Terry','Yoakum','Cochran','Hockley','Lubbock','Bailey',\n",
    "                      'Lamb','Hartley','Dallam','Moore','Sherman','Hansford','Hutchinson','Ochiltree','Lipscomb', \n",
    "                      'Hemphill','Bowie','Morris','Cass','Camp','Marion','Upshur','Gregg','Harrison','Panola',\n",
    "                      'Shelby','San Augustine','Sabine','Trinity','Polk','Tyler','Jasper','Newton','San Jacinto',\n",
    "                      'Hardin','Liberty','Orange','Jefferson']\n",
    "\n",
    "removec = [count + ' County' for count in non_ercot_counties]\n",
    "\n",
    "cdat = pd.read_excel(icd, usecols=['County'])\n",
    "counties = cdat['County'].to_list()\n",
    "\n",
    "for count in removec:\n",
    "    counties.remove(count)\n",
    "\n",
    "print(len(counties))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have stored all data NREL Wind Toolkit and SAM Solar data in google drive for space considerations.\n",
    "Pydrive is being employed to access and work with this data - next 3 blocks are for doing this.\n",
    "Data is converted to 'Wind2009.csv' type files, which are used in modeling and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=62179872653-sp0h6kju465i2lb634qqqqtlkogst5fk.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n"
     ]
    }
   ],
   "source": [
    "#pydrive quickstart google authorization\n",
    "from pydrive.auth import GoogleAuth\n",
    "\n",
    "gauth = GoogleAuth()\n",
    "gauth.LocalWebserverAuth() # Creates local webserver and auto handles authentication.\n",
    "\n",
    "#pydrive drive interaction\n",
    "from pydrive.drive import GoogleDrive\n",
    "\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solar reformatting\n",
    "\n",
    "#get files from drive\n",
    "file_list = drive.ListFile({'q': \"'' in parents and trashed=false\"}).GetList()\n",
    "print(len(file_list))\n",
    "#2009 - 1kG13cMZ0XdGwO3lA1x_2C7QlWIj2SKUH\n",
    "#2010 - 1WkUW03_DWJqj5OgYpNe9bsijrtUwQzJc\n",
    "#2011 - 1pqhBKFg6FGNOqTwyNs9dq5J2XChaWBUh\n",
    "\n",
    "#reformatting - want average capacity of all coordinates within county\n",
    "countydic = dict.fromkeys(counties,np.zeros(17520)) #every half hour\n",
    "countdic = dict.fromkeys(counties,0)\n",
    "wcn = 0 #how many points in our mesh grid are not within an ERCOT county\n",
    "\n",
    "for file in file_list:\n",
    "    name = file['title']\n",
    "    lat = name.split('lat')[1]\n",
    "    [lat,lon] = lat.split('lon')\n",
    "    lon = lon.split('.csv')[0]\n",
    "    lon = lon.split(' ')[0]\n",
    "    coordinates = (float(lat),float(lon))\n",
    "    county = rg.search(coordinates)[0]['admin2'] #reverse_geocoder used to site coordinates in county\n",
    "    print(county)\n",
    "    if county in counties:\n",
    "        file = drive.CreateFile({'id': file['id']})\n",
    "        file.GetContentFile('file.csv')\n",
    "        pdat = pd.read_csv('file.csv', usecols=['PowerGen_kW'],dtype=np.float).to_numpy()\n",
    "        pdat = [float(i) for i in pdat]\n",
    "        countydic[county] = countydic[county] + pdat\n",
    "        countdic[county] += 1\n",
    "    else:\n",
    "        wcn += 1\n",
    "\n",
    "nameplate_cap = 22557.15 #nameplate capacity of used sample sites in kW\n",
    "outdic = dict.fromkeys(counties,np.zeros(17520))\n",
    "for county in counties:\n",
    "    if countdic[county] != 0:\n",
    "        #computing average solar capacity within each county\n",
    "        outdic[county] = countydic[county] / (countdic[county]*nameplate_cap)\n",
    "\n",
    "df = pd.DataFrame(data=outdic).to_csv('Solar.csv')\n",
    "\n",
    "print(wcn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading formatted geocoded file...\n"
     ]
    }
   ],
   "source": [
    "#wind reformatting\n",
    "\n",
    "#get files from drive\n",
    "file_list = drive.ListFile({'q': \"'1H40oHl84pa8iaJ7xY4UpUlY78kvMlc2l' in parents and trashed=false\"}).GetList()\n",
    "#reformatting - if you want max site per county\n",
    "countydic = {}\n",
    "sumdic = defaultdict(int) #keeping track of best site so far (in terms of average capacity factor)\n",
    "#filedic = {} #keeping track of best location within each county - not necesary\n",
    "wcn = 0 #how many points in our mesh grid are not within an ERCOT county\n",
    "\n",
    "#if you want average per county\n",
    "countydic = dict.fromkeys(counties,np.zeros(17520)) #every half hour\n",
    "countdic = dict.fromkeys(counties,0)\n",
    "\n",
    "for file in file_list:\n",
    "    name = file['title']\n",
    "    lat = name.split('lat')[1]\n",
    "    [lat,lon] = lat.split('lon')\n",
    "    lon = lon.split('.csv')[0]\n",
    "    coordinates = (float(lat),float(lon))\n",
    "    county = rg.search(coordinates)[0]['admin2']\n",
    "    if county in counties:\n",
    "        file = drive.CreateFile({'id': file['id']})\n",
    "        file.GetContentFile('file.csv')\n",
    "        pdat = pd.read_csv('file.csv', skiprows=3, usecols=['Capacity Factor'],dtype=np.float, engine='python').to_numpy()\n",
    "        dat = []\n",
    "        ssum = 0\n",
    "        for hour in range(17520):\n",
    "            power = sum([float(i) for i in pdat[(6*hour):(6*(hour+1))]]) / 6 #5 min --> 30 min intervals\n",
    "            dat.append(power)\n",
    "            ssum += power\n",
    "        #for getting max site\n",
    "#         if ssum > sumdic[county]: #is this site \"better\" than current best site in county\n",
    "#             countydic[county] = dat\n",
    "#             sumdic[county] = ssum\n",
    "            #filedic[county] = [lat,lon]\n",
    "            #capdic[county] = scap\n",
    "        \n",
    "        #for getting average site\n",
    "        countydic[county] = countydic[county] + dat\n",
    "        countdic[county] += 1    \n",
    "    else:\n",
    "        wcn += 1\n",
    "\n",
    "#for getting average site, need to take average\n",
    "outdic = dict.fromkeys(counties,np.zeros(17520))\n",
    "for county in counties:\n",
    "    if countdic[county] != 0:\n",
    "        outdic[county] = countydic[county] / (countdic[county])\n",
    "\n",
    "pd.DataFrame(data=outdic).to_csv('Wind.csv')\n",
    "print(wcn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import energy price data by the half hour for each load region\n",
    "#not using HB_HOUSTON (houston hub), COAST --> HB_SOUTH, NORTH --> HB_WEST\n",
    "y = 17520\n",
    "loadzones = ['HB_NORTH', 'HB_SOUTH', 'HB_WEST']\n",
    "loadprices = dict.fromkeys(loadzones,np.empty(0))\n",
    "\n",
    "epsheet = 'EnergyPricesERCOT2019.xlsx'\n",
    "months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "xls = pd.ExcelFile(epsheet)\n",
    "\n",
    "for i in range(12):\n",
    "    df = pd.read_excel(xls, months[i], usecols=['Settlement Point Name','Repeated Hour Flag','Settlement Point Price'])\n",
    "    df = df.loc[df['Repeated Hour Flag']=='N']\n",
    "    for zone in loadzones:\n",
    "        eprice = df.loc[df['Settlement Point Name']==zone]['Settlement Point Price'].to_numpy()\n",
    "        eprice = (eprice[::2] + eprice[1::2])/2\n",
    "        loadprices[zone] = np.hstack((loadprices[zone],eprice))\n",
    "\n",
    "#godam daylight savings time\n",
    "for zone in loadzones:\n",
    "    eprice = loadprices[zone]\n",
    "    eprice = np.concatenate((eprice[0:3268],np.array([eprice[3267],eprice[3268]]),eprice[3268:17518]))\n",
    "    loadprices[zone] = eprice\n",
    "\n",
    "pd.DataFrame(data=loadprices).to_csv('EnergyPriceNew2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR RUNNING ACTUAL OPTIMIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REGIONS (if u want)\n",
    "\n",
    "from uszipcode import SearchEngine\n",
    "search = SearchEngine(simple_zipcode=True)\n",
    "\n",
    "pdat = pd.read_excel('Zipcode_Data.xlsx', sheet_name='ZipToZone', usecols=['Svc. Address ZIP Code','Weather Zone Code'])\n",
    "\n",
    "#removing zipcodes outside of ERCOT, one's with discrespancies just keeping cuz they dont even know wuts right\n",
    "update = pd.read_excel('Zipcode_Data_Update.xlsx', sheet_name='D1', skiprows=3, usecols=['Zipcode']).to_numpy().flatten()\n",
    "dropidx = pdat.index[pdat['Svc. Address ZIP Code'].isin(update)].to_list()\n",
    "\n",
    "pdat = pdat.drop(dropidx)\n",
    "\n",
    "regions = np.array(['NORTH', 'NCENT', 'EAST', 'COAST', 'SOUTH', 'SCENT', 'WEST', 'FWEST']) #easier if numpy array\n",
    "regdict = {'NORTH': [], 'NCENT': [], 'EAST': [], 'COAST': [], 'SOUTH': [], 'SCENT': [], 'WEST': [], 'FWEST': []}\n",
    "\n",
    "for i,row in pdat.iterrows():\n",
    "    zipcode = str(row['Svc. Address ZIP Code'])\n",
    "    region = str(row['Weather Zone Code'])\n",
    "    county = search.by_zipcode(zipcode).to_dict()['county']\n",
    "    regdict[region].append(county)\n",
    "    \n",
    "#could put multiple region counties in primary region or just leave in multiple regions\n",
    "#every county pretty dominantly in one county except austin (even split)\n",
    "simpregdict = {}\n",
    "multregdict = {}\n",
    "for county in counties:\n",
    "    counter = []\n",
    "    for reg in regions:\n",
    "        counter.append(regdict[reg].count(county))\n",
    "    simpregion = regions[np.argmax(counter)]\n",
    "    multregions = list(regions[[i for i, val in enumerate(counter) if val != 0]])\n",
    "    simpregdict[county] = simpregion #for simple can do county --> region cause only 1 region per county\n",
    "    multregdict[county] = multregions\n",
    "\n",
    "simpregdict['Austin County'] = 'SCENT' #austin between two zones put in SCENT b/c map looks like that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#months (if u want)\n",
    "days = np.array([31,28,31,30,31,30,31,31,30,31,30,31]); halfhours = days*48; hsums = []\n",
    "for month in range(12):\n",
    "    hsums.append(sum(halfhours[:month]))\n",
    "hsums.append(17520)\n",
    "months = ['January','February','March','April','May','June','July','August','September','October','November','December']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IF DOING FREE MODEL (all counties available)\n",
    "\n",
    "solarcounts = counties\n",
    "solarcnum = len(solarcounts)\n",
    "solarcaps = np.ones(solarcnum)\n",
    "solarnames = [solarcounts[i] + ' Solar: ' for i in range(solarcnum)]\n",
    "\n",
    "windcounts = counties\n",
    "windcnum = len(windcounts)\n",
    "windcaps = np.ones(windcnum)\n",
    "windnames = [windcounts[i] + ' Wind: ' for i in range(solarcnum)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262\n",
      "108\n",
      "58014.529999999984\n",
      "24588.49\n",
      "610.0\n",
      "630.0\n"
     ]
    }
   ],
   "source": [
    "#IF USING GIS REPORT (SKIP if doing free model)\n",
    "\n",
    "#import GIS site data\n",
    "gisreport = 'Ercot_GIS_Report_June.xlsx'\n",
    "pdat = pd.read_excel(gisreport, sheet_name='Project Details', usecols=['GINR Study Phase','County','Fuel','Capacity (MW)'])\n",
    "\n",
    "#only care about sites which already have IA agreement (for now)\n",
    "names = [\"SS Completed, FIS Completed, IA\", \"SS Completed, FIS Started, IA\",\"SS Completed, FIS Completed, No IA\",\n",
    "        \"SS Completed, FIS Started, No IA\"]\n",
    "#pdat = pdat.loc[pdat['GINR Study Phase'].isin(names)]\n",
    "\n",
    "solarp = pdat.loc[pdat['Fuel']==\"SOL\"]\n",
    "solarp = solarp.loc[solarp['Capacity (MW)'] > 0] #some caps 0 - don't need to remove technically but y not\n",
    "#solarp = solarp.loc[simpregdict[solarp['County'] + ' County'] == 'SCENT'] #for jkspruce model\n",
    "\n",
    "ogsolarcounts = solarp['County'].to_list()\n",
    "solarcounts = [count + ' County' for count in ogsolarcounts]\n",
    "solarcaps = solarp['Capacity (MW)'].to_numpy()\n",
    "solarcnum = len(solarcounts)\n",
    "\n",
    "windp = pdat.loc[pdat['Fuel']==\"WIN\"]\n",
    "windp = windp.loc[windp['Capacity (MW)'] > 0] \n",
    "#windp = windp.loc[simpregdict[windp['County'] + ' County'] == 'SCENT'] #for jkspruce model\n",
    "\n",
    "ogwindcounts = windp['County'].to_list()\n",
    "windcounts = [count + ' County' for count in ogwindcounts]\n",
    "windcaps = windp['Capacity (MW)'].to_numpy()\n",
    "windcnum = len(windcounts)\n",
    "\n",
    "solarnames = [solarcounts[i] + ' Solar: ' + str(solarcaps[i]) for i in range(solarcnum)]\n",
    "windnames = [windcounts[i] + ' Wind: ' + str(windcaps[i]) for i in range(windcnum)] \n",
    "\n",
    "####for checking if things ran correctly\n",
    "print(solarcnum)\n",
    "print(windcnum)\n",
    "\n",
    "print(sum(solarcaps))\n",
    "print(sum(windcaps))\n",
    "print(max(solarcaps))\n",
    "print(max(windcaps))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52560, 213)\n"
     ]
    }
   ],
   "source": [
    "#import formatted power data and scale up by site capacity, put in matrix form\n",
    "solarcsvs = ['NewSolar2009.csv','NewSolar2010.csv','NewSolar2011.csv']\n",
    "solartraincsvs = solarcsvs\n",
    "solartestcsvs = []\n",
    "solarpower = np.empty((solarcnum,0))\n",
    "solarpowertest = np.empty((solarcnum,0))\n",
    "hl = 1 #working with half hours so hour-length = 0.5\n",
    "\n",
    "for solarcsv in solartraincsvs:\n",
    "    pdat = pd.read_csv(solarcsv, usecols=solarcounts)\n",
    "    solaryear = pdat[solarcounts[0]].to_numpy() * solarcaps[0] * hl #0th\n",
    "    for i in range(solarcnum-1): #1th onwards\n",
    "        solaryear = np.vstack((solaryear,pdat[solarcounts[i+1]].to_numpy() * solarcaps[i+1] * hl))\n",
    "    solarpower = np.concatenate((solarpower,solaryear),axis=1) #div by 2 to convert from MW (power) to MWh (energy output)\n",
    "\n",
    "for solarcsv in solartestcsvs:\n",
    "    pdat = pd.read_csv(solarcsv, usecols=solarcounts)\n",
    "    solaryear = pdat[solarcounts[0]].to_numpy() * solarcaps[0] * hl #0th\n",
    "    for i in range(solarcnum-1): #1th onwards\n",
    "        solaryear = np.vstack((solaryear,pdat[solarcounts[i+1]].to_numpy() * solarcaps[i+1] * hl))\n",
    "    solarpowertest = np.concatenate((solarpowertest,solaryear),axis=1)\n",
    "\n",
    "windcsvs = ['CountyWind2009.csv','Wind2010.csv','Wind2011.csv']\n",
    "windcsvsavg = ['WindAvg2009.csv','WindAvg2010.csv','WindAvg2011.csv']\n",
    "windtraincsvs = windcsvs\n",
    "windtestcsvs = []\n",
    "windpower = np.empty((windcnum,0))\n",
    "windpowertest = np.empty((windcnum,0))\n",
    "\n",
    "for windcsv in windtraincsvs:\n",
    "    pdat = pd.read_csv(windcsv, usecols=windcounts)\n",
    "    windyear = pdat[windcounts[0]].to_numpy() * windcaps[0] * hl #0th\n",
    "    for i in range(windcnum-1): #1th onwards\n",
    "        windyear = np.vstack((windyear,pdat[windcounts[i+1]].to_numpy() * windcaps[i+1] * hl))\n",
    "    windpower = np.concatenate((windpower,windyear),axis=1)\n",
    "    \n",
    "for windcsv in windtestcsvs:\n",
    "    pdat = pd.read_csv(windcsv, usecols=windcounts)\n",
    "    windyear = pdat[windcounts[0]].to_numpy() * windcaps[0] * hl #0th\n",
    "    for i in range(windcnum-1): #1th onwards\n",
    "        windyear = np.vstack((windyear,pdat[windcounts[i+1]].to_numpy() * windcaps[i+1] * hl))\n",
    "    windpowertest = np.concatenate((windpowertest,windyear),axis=1)\n",
    "    \n",
    "solarpower = np.transpose(solarpower)\n",
    "windpower = np.transpose(windpower)\n",
    "solarpowertest = np.transpose(solarpowertest)\n",
    "windpowertest = np.transpose(windpowertest)\n",
    "\n",
    "print(solarpower.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Andrews County', 'Angelina County', 'Aransas County', 'Archer County', 'Armstrong County', 'Atascosa County', 'Austin County', 'Bandera County', 'Bastrop County']\n"
     ]
    }
   ],
   "source": [
    "sp = sum(solarpower) / 52560\n",
    "wp = sum(windpower) / 52560\n",
    "outdic = {'County': counties, 'Solar': sp, 'Wind': wp}\n",
    "print(counties[1:10])\n",
    "#pd.DataFrame(data=outdic).to_csv('Fig6Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06252267035806358\n",
      "0.052028138497158184\n"
     ]
    }
   ],
   "source": [
    "print(dsum[windcounts.index('Pecos County')])\n",
    "print(dsum[windcounts.index('Willacy County')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import coal data and format to be by the half hour\n",
    "\n",
    "fuel = 'Fuel2019.xlsx'\n",
    "months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "xls = pd.ExcelFile(fuel)\n",
    "\n",
    "coalhours = np.empty(0)\n",
    "\n",
    "for i in range(12):\n",
    "    dat = pd.read_excel(xls, months[i])\n",
    "    coal = dat.loc[dat['Fuel']==\"Coal\"]\n",
    "    coal = coal[coal.columns[4::2]].to_numpy() + coal[coal.columns[5::2]].to_numpy() #every half hour\n",
    "    coal = np.reshape(coal,np.prod(coal.shape))\n",
    "    coalhours = np.concatenate((coalhours,coal))\n",
    "coalhours = np.nan_to_num(coalhours)\n",
    "\n",
    "#coal = 'Coal2019.csv'\n",
    "#coalhours = pd.read_csv(coal,usecols=['Coal']).to_numpy()\n",
    "\n",
    "coalhours = np.hstack((coalhours,coalhours,coalhours))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdic = {}\n",
    "for m in range(12):\n",
    "    avg = np.empty(48)\n",
    "    month = coalhours[hsums[m]:hsums[m+1]]\n",
    "    for hh in range(48):\n",
    "        avg[hh] = sum(month[hh::48]) / days[m]\n",
    "    outdic[months[m]] = avg\n",
    "pd.DataFrame(data=outdic).to_csv('CoalSupplement.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import coal plant data and format to be regional\n",
    "coalcsv = 'EPA_Coal_2019.csv'\n",
    "pdat = pd.read_csv(coalcsv,usecols=['Facility_Name','Gross_Load_MW'])\n",
    "\n",
    "oklaunion = pdat.loc[pdat['Facility_Name']==\"Oklaunion Power Station\"]['Gross_Load_MW'].to_numpy()\n",
    "coletocreek = pdat.loc[pdat['Facility_Name']==\"Coleto Creek\"]['Gross_Load_MW'].to_numpy()\n",
    "martinlake = pdat.loc[pdat['Facility_Name']==\"Martin Lake\"]['Gross_Load_MW'].to_numpy()\n",
    "fayette = pdat.loc[pdat['Facility_Name']==\"Sam Seymour\"]['Gross_Load_MW'].to_numpy()\n",
    "sanmiguel = pdat.loc[pdat['Facility_Name']==\"San Miguel\"]['Gross_Load_MW'].to_numpy()\n",
    "sandycreek = pdat.loc[pdat['Facility_Name']==\"Sandy Creek Energy Station\"]['Gross_Load_MW'].to_numpy()\n",
    "oakgrove = pdat.loc[pdat['Facility_Name']==\"Oak Grove\"]['Gross_Load_MW'].to_numpy()\n",
    "jkspruce = pdat.loc[pdat['Facility_Name']==\"J K Spruce\"]['Gross_Load_MW'].to_numpy()\n",
    "limestone = pdat.loc[pdat['Facility_Name']==\"Limestone\"]['Gross_Load_MW'].to_numpy()\n",
    "waparish = pdat.loc[pdat['Facility_Name']==\"W A Parish\"]['Gross_Load_MW'].to_numpy()\n",
    "twinoaks = pdat.loc[pdat['Facility_Name']==\"Twin Oaks\"]['Gross_Load_MW'].to_numpy()\n",
    "#welsh = pdat.loc[pdat['Facility_Name']==\"Welsh Power Plant\"]['Gross_Load_MW'].to_numpy()\n",
    "\n",
    "#costs = [0, 120.2, 102.2, 84.35, 126.34, 0, 79.02, 89.53, 102.48, 163.99, 0, 116.6]\n",
    "    \n",
    "southcoal = coletocreek + sanmiguel\n",
    "scentcoal = jkspruce + fayette\n",
    "ncentcoal = limestone + sandycreek\n",
    "northcoal = oklaunion\n",
    "eastcoal = martinlake + oakgrove + twinoaks\n",
    "coastcoal = waparish\n",
    "westcoal = np.zeros(8760)\n",
    "fwestcoal = np.zeros(8760)\n",
    "allcoalplants = southcoal + scentcoal + ncentcoal + northcoal + eastcoal + coastcoal + westcoal + fwestcoal\n",
    "\n",
    "coalload = {'HB_NORTH': ncentcoal + eastcoal, 'HB_SOUTH': southcoal + scentcoal + coastcoal, 'HB_WEST': westcoal + fwestcoal + northcoal}\n",
    "coalregs = {'NORTH': northcoal, 'NCENT': ncentcoal, 'EAST': eastcoal, 'COAST': coastcoal, 'SOUTH': southcoal, 'SCENT': scentcoal, 'WEST': westcoal, 'FWEST': fwestcoal, 'All': allcoalplants}\n",
    "coalregscf = {}\n",
    "for reg, regcoal in coalregs.items():\n",
    "#    coalregs[reg] = np.hstack((regcoal,regcoal,regcoal))\n",
    "    m = max(regcoal)\n",
    "    if m < 0.1:\n",
    "        coalregscf[reg] = regcoal\n",
    "    else:\n",
    "        coalregscf[reg] = regcoal / max(regcoal)\n",
    "\n",
    "#San Miguel in Atascosa county which is 9/10 zipcodes in SOUTH (and 1 in SCENT) --> putting in south"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadzones = ['HB_NORTH', 'HB_SOUTH', 'HB_WEST']\n",
    "weathertoload = {'NORTH': 'HB_WEST', 'NCENT': 'HB_NORTH', 'EAST': 'HB_NORTH', 'COAST': 'HB_SOUTH', 'SOUTH': 'HB_SOUTH', 'SCENT': 'HB_SOUTH', 'WEST': 'HB_WEST', 'FWEST': 'HB_WEST'}\n",
    "energyprice = pd.read_csv('EnergyPriceAgg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cost data\n",
    "sc = 92.50*1000 # LCOE $ / MW-Cap \n",
    "solarcost = sc*solarcaps\n",
    "wc = 118.48*1000 # LCOE $ / MW-Cap \n",
    "windcost = wc*windcaps\n",
    "coalcost = 111.67 # $ / MWh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.043012797958400684\n",
      "0.12203196347031964\n",
      "3.0\n",
      "6949.897196\n",
      "8.2795883202\n",
      "82.60301999999999\n"
     ]
    }
   ],
   "source": [
    "#Exploratory analysis - 2300 infeasible hours and 5 wind cites with 0 capacity! (to go along w/ the negative ones)\n",
    "coaltotal = sum(coalhours)\n",
    "h = len(coalhours)\n",
    "\n",
    "spv = np.sum(solarpower, axis=1); wpv = np.sum(windpower, axis=1);\n",
    "allpower = spv + wpv\n",
    "feasible = [i for i in range(h) if allpower[i] >= coalhours[i]]\n",
    "feasn = len(feasible)\n",
    "\n",
    "#slackbound = 0.01*coalhours #percent of hour demand I allow to be slacked\n",
    "maxcap = 1 #set to linear max for linear case\n",
    "infeasibility = 0\n",
    "infhours = 0\n",
    "badhours = []\n",
    "si = 0\n",
    "wi = 0\n",
    "for i in range(h):\n",
    "    dif = coalhours[i] - maxcap*(allpower[i])\n",
    "    sd = coalhours[i] - spv[i]\n",
    "    wd = coalhours[i] - wpv[i]\n",
    "    if dif > 0:\n",
    "        infeasibility += dif\n",
    "        infhours += 1\n",
    "        badhours.append(i)\n",
    "        #slackbound[i] += dif\n",
    "    if sd > 0:\n",
    "        si += sd\n",
    "    if wd > 0:\n",
    "        wi += wd\n",
    "        \n",
    "slacknames = ['Slack:' + str(i) for i in range(h)] # also need this for naming zeta (hour) variables\n",
    "xsnames = ['Excess:' + str(i) for i in range(h)]\n",
    "\n",
    "#slowbound = 1\n",
    "#wlowbound = 1\n",
    "#energy_price = 50\n",
    "\n",
    "print(infeasibility/coaltotal)\n",
    "# print(si / coaltotal)\n",
    "# print(wi / coaltotal)\n",
    "print(infhours/h)\n",
    "print(h / (48*365))\n",
    "print(max(coalhours))\n",
    "\n",
    "print((sum(solarcost) + sum(windcost)) / 10**9)\n",
    "print((sum(solarcaps) + sum(windcaps)) / 10**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using license file /Users/richard.morse/gurobi.lic\n",
      "Academic license - for non-commercial use only - expires 2021-07-22\n",
      "Gurobi Optimizer version 9.1.0 build v9.1.0rc0 (mac64)\n",
      "Thread count: 2 physical cores, 4 logical processors, using up to 4 threads\n",
      "Optimize a model with 52561 rows, 52930 columns and 19487667 nonzeros\n",
      "Model fingerprint: 0x0729fb43\n",
      "Variable types: 52560 continuous, 370 integer (370 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [3e-06, 3e+02]\n",
      "  Objective range  [2e+05, 7e+07]\n",
      "  Bounds range     [1e+00, 7e+03]\n",
      "  RHS range        [1e+03, 2e+07]\n",
      "Found heuristic solution: objective 8.132089e+09\n",
      "Presolve removed 0 rows and 0 columns (presolve time = 5s) ...\n",
      "Presolve removed 0 rows and 28 columns (presolve time = 45s) ...\n",
      "Presolve removed 0 rows and 28 columns (presolve time = 46s) ...\n",
      "Presolve removed 6395 rows and 6423 columns (presolve time = 60s) ...\n",
      "Presolve removed 6395 rows and 6423 columns (presolve time = 60s) ...\n",
      "Presolve removed 6395 rows and 6425 columns (presolve time = 97s) ...\n",
      "Presolve removed 6395 rows and 6425 columns (presolve time = 107s) ...\n",
      "Presolve removed 6395 rows and 6425 columns (presolve time = 131s) ...\n",
      "Presolve removed 6662 rows and 6692 columns (presolve time = 137s) ...\n",
      "Presolve removed 6384 rows and 6414 columns\n",
      "Presolve time: 136.75s\n",
      "Presolved: 46177 rows, 46516 columns, 14723757 nonzeros\n",
      "Variable types: 46165 continuous, 351 integer (321 binary)\n",
      "\n",
      "Deterministic concurrent LP optimizer: dual simplex and barrier\n",
      "Showing barrier log only...\n",
      "\n",
      "Root barrier log...\n",
      "\n",
      "Ordering time: 1.01s\n",
      "\n",
      "Barrier statistics:\n",
      " Dense cols : 346\n",
      " AA' NZ     : 1.445e+07\n",
      " Factor NZ  : 1.508e+07 (roughly 160 MBytes of memory)\n",
      " Factor Ops : 4.946e+09 (roughly 1 second per iteration)\n",
      " Threads    : 1\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   9.01790669e+12 -3.41822997e+12  1.49e+07 1.08e+03  5.87e+09   169s\n",
      "   1   4.97108407e+12 -3.39802109e+12  8.06e+06 1.47e+05  3.04e+09   171s\n",
      "   2   3.69144247e+12 -3.32606009e+12  5.51e+06 7.14e+04  2.04e+09   172s\n",
      "   3   3.34825309e+12 -3.48573688e+12  4.95e+06 2.15e+04  1.63e+09   174s\n",
      "   4   1.09313731e+12 -3.56316423e+12  1.48e+06 2.99e+03  4.83e+08   175s\n",
      "   5   4.80515085e+11 -3.25623856e+12  5.02e+05 2.81e+02  1.67e+08   177s\n",
      "   6   1.48724660e+11 -1.98972087e+12  1.34e+05 2.41e-05  4.79e+07   179s\n",
      "   7   1.51570773e+10 -7.13606358e+11  6.53e+03 5.91e-05  6.34e+06   181s\n",
      "   8   9.92653122e+09 -2.36229171e+11  1.80e+03 1.98e-05  1.91e+06   182s\n",
      "   9   9.00414365e+09 -1.25732548e+11  1.13e+03 6.98e-05  1.02e+06   183s\n",
      "  10   8.87091974e+09 -1.21965056e+11  1.07e+03 6.95e-05  9.85e+05   185s\n",
      "  11   8.75002761e+09 -1.07143426e+11  1.03e+03 7.22e-05  8.70e+05   186s\n",
      "  12   7.58353715e+09 -8.49032625e+10  5.71e+02 5.79e-05  6.83e+05   187s\n",
      "  13   6.83802712e+09 -5.96794196e+10  3.98e+02 3.91e-05  4.88e+05   189s\n",
      "  14   6.26104370e+09 -4.11838736e+10  2.68e+02 2.75e-05  3.46e+05   190s\n",
      "  15   5.83989829e+09 -3.55656220e+10  1.76e+02 2.41e-05  3.01e+05   191s\n",
      "  16   5.49229522e+09 -2.87020630e+10  9.37e+01 1.97e-05  2.48e+05   193s\n",
      "  17   5.22335564e+09 -2.35612393e+10  3.82e+01 1.65e-05  2.08e+05   194s\n",
      "  18   4.94267766e+09 -1.62208869e+10  1.75e+00 1.21e-05  1.53e+05   196s\n",
      "  19   4.77900208e+09 -1.46888052e+10  1.47e+00 1.12e-05  1.40e+05   197s\n",
      "  20   4.64957393e+09 -1.31374149e+10  1.21e+00 1.03e-05  1.28e+05   198s\n",
      "  21   4.51077077e+09 -1.15573815e+10  8.75e-01 9.32e-06  1.16e+05   200s\n",
      "  22   4.37498936e+09 -7.77901992e+09  5.76e-01 7.04e-06  8.73e+04   201s\n",
      "  23   4.31316228e+09 -6.88377813e+09  4.85e-01 6.47e-06  8.04e+04   204s\n",
      "  24   4.15336850e+09 -2.67700091e+09  1.78e-01 3.82e-06  4.90e+04   206s\n",
      "  25   4.00612606e+09 -1.66124681e+09  7.58e-02 3.22e-06  4.07e+04   207s\n",
      "  26   3.98283405e+09  4.75416055e+08  6.91e-02 1.91e-06  2.52e+04   209s\n",
      "  27   3.94854121e+09  4.86899496e+08  6.60e-02 1.91e-06  2.49e+04   210s\n",
      "  28   3.91609794e+09  5.97130677e+08  6.36e-02 1.83e-06  2.38e+04   211s\n",
      "  29   3.82141777e+09  1.10195975e+09  5.65e-02 1.42e-06  1.95e+04   213s\n",
      "  30   3.73363683e+09  1.53093311e+09  4.88e-02 1.10e-06  1.58e+04   214s\n",
      "  31   3.65359736e+09  1.79342671e+09  4.32e-02 9.16e-07  1.33e+04   215s\n",
      "  32   3.56739130e+09  1.93255734e+09  3.55e-02 7.99e-07  1.17e+04   217s\n",
      "  33   3.51457102e+09  2.14368791e+09  3.18e-02 6.35e-07  9.84e+03   218s\n",
      "  34   3.49627531e+09  2.21557120e+09  3.03e-02 6.32e-07  9.19e+03   220s\n",
      "  35   3.39169304e+09  2.34557407e+09  2.31e-02 5.24e-07  7.51e+03   221s\n",
      "  36   3.35196685e+09  2.45023589e+09  2.07e-02 4.31e-07  6.47e+03   223s\n",
      "  37   3.30656837e+09  2.56434212e+09  1.77e-02 3.62e-07  5.33e+03   224s\n",
      "  38   3.26887115e+09  2.65967072e+09  1.54e-02 2.68e-07  4.37e+03   226s\n",
      "  39   3.19809040e+09  2.74273169e+09  1.08e-02 1.91e-07  3.27e+03   227s\n",
      "  40   3.15061055e+09  2.77606918e+09  7.80e-03 1.68e-07  2.69e+03   228s\n",
      "  41   3.13210847e+09  2.88218372e+09  6.64e-03 1.03e-07  1.79e+03   230s\n",
      "  42   3.10206343e+09  2.93561654e+09  4.78e-03 8.80e-08  1.19e+03   232s\n",
      "  43   3.07956407e+09  2.97989056e+09  3.44e-03 5.31e-08  7.15e+02   233s\n",
      "  44   3.06819947e+09  2.99909496e+09  2.77e-03 3.82e-08  4.95e+02   234s\n",
      "  45   3.06296621e+09  3.00494756e+09  2.42e-03 5.82e-08  4.16e+02   236s\n",
      "  46   3.04820453e+09  3.01198150e+09  1.53e-03 4.14e-08  2.60e+02   237s\n",
      "  47   3.03701344e+09  3.01461760e+09  8.89e-04 5.40e-08  1.61e+02   238s\n",
      "  48   3.03236313e+09  3.01936504e+09  6.21e-04 4.19e-08  9.32e+01   240s\n",
      "  49   3.03068328e+09  3.02058231e+09  5.38e-04 3.91e-08  7.24e+01   242s\n",
      "  50   3.02783069e+09  3.02100293e+09  3.69e-04 7.54e-08  4.89e+01   243s\n",
      "  51   3.02535908e+09  3.02122119e+09  2.16e-04 3.91e-08  2.96e+01   245s\n",
      "  52   3.02381026e+09  3.02151833e+09  1.23e-04 6.05e-08  1.64e+01   246s\n",
      "  53   3.02266611e+09  3.02164132e+09  5.53e-05 4.10e-08  7.34e+00   248s\n",
      "  54   3.02226117e+09  3.02170967e+09  3.23e-05 4.05e-08  3.95e+00   249s\n",
      "  55   3.02197916e+09  3.02171805e+09  1.68e-05 7.73e-08  1.87e+00   251s\n",
      "  56   3.02179171e+09  3.02171722e+09  3.68e-06 6.15e-08  5.34e-01   252s\n",
      "  57   3.02178613e+09  3.02171861e+09  3.40e-06 6.85e-08  4.84e-01   254s\n",
      "  58   3.02176663e+09  3.02172090e+09  2.90e-06 5.36e-08  3.28e-01   255s\n",
      "  59   3.02172776e+09  3.02172022e+09  7.50e-07 7.64e-08  5.41e-02   257s\n",
      "  60   3.02172157e+09  3.02172142e+09  1.49e-07 4.38e-08  1.03e-03   258s\n",
      "  61   3.02172149e+09  3.02172149e+09  1.74e-10 1.47e-06  1.46e-06   260s\n",
      "  62   3.02172149e+09  3.02172149e+09  2.28e-12 1.68e-06  2.11e-08   262s\n",
      "  63   3.02172149e+09  3.02172149e+09  1.44e-09 1.23e-05  2.12e-11   264s\n",
      "\n",
      "Barrier solved model in 63 iterations and 263.57 seconds\n",
      "Optimal objective 3.02172149e+09\n",
      "\n",
      "\n",
      "Root crossover log...\n",
      "\n",
      "      14 DPushes remaining with DInf 0.0000000e+00               264s\n",
      "       0 DPushes remaining with DInf 0.0000000e+00               265s\n",
      "\n",
      "       4 PPushes remaining with PInf 0.0000000e+00               265s\n",
      "       0 PPushes remaining with PInf 0.0000000e+00               266s\n",
      "\n",
      "  Push phase complete: Pinf 0.0000000e+00, Dinf 1.2282283e-07    266s\n",
      "\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "      21    3.0217215e+09   0.000000e+00   0.000000e+00    267s\n",
      "      21    3.0217215e+09   0.000000e+00   0.000000e+00    269s\n",
      "Concurrent spin time: 0.01s\n",
      "\n",
      "Solved with barrier\n",
      "\n",
      "Root relaxation: objective 3.021721e+09, 21 iterations, 119.71 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 3.0217e+09    0    3 8.1321e+09 3.0217e+09  62.8%     -  270s\n",
      "H    0     0                    3.038509e+09 3.0217e+09  0.55%     -  272s\n",
      "H    0     0                    3.022699e+09 3.0217e+09  0.03%     -  275s\n",
      "     0     0 3.0217e+09    0    3 3.0227e+09 3.0217e+09  0.03%     -  287s\n",
      "     0     0 3.0217e+09    0    3 3.0227e+09 3.0217e+09  0.03%     -  673s\n",
      "     0     0 3.0217e+09    0    3 3.0227e+09 3.0217e+09  0.03%     -  678s\n",
      "     0     0 3.0217e+09    0    3 3.0227e+09 3.0217e+09  0.03%     -  682s\n",
      "     0     0 3.0217e+09    0    3 3.0227e+09 3.0217e+09  0.03%     -  684s\n",
      "     0     0 3.0217e+09    0    3 3.0227e+09 3.0217e+09  0.03%     -  685s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0     0 3.0217e+09    0    3 3.0227e+09 3.0217e+09  0.03%     -  687s\n",
      "     0     0 3.0217e+09    0    3 3.0227e+09 3.0217e+09  0.03%     -  688s\n",
      "     0     0 3.0217e+09    0    3 3.0227e+09 3.0217e+09  0.03%     -  689s\n",
      "     0     0 3.0217e+09    0    3 3.0227e+09 3.0217e+09  0.03%     -  691s\n",
      "     0     0 3.0217e+09    0    3 3.0227e+09 3.0217e+09  0.03%     -  692s\n",
      "     0     0 3.0217e+09    0    5 3.0227e+09 3.0217e+09  0.03%     -  693s\n",
      "     0     0 3.0217e+09    0    5 3.0227e+09 3.0217e+09  0.03%     -  695s\n",
      "     0     0 3.0217e+09    0    5 3.0227e+09 3.0217e+09  0.03%     -  696s\n",
      "     0     0 3.0217e+09    0    5 3.0227e+09 3.0217e+09  0.03%     -  697s\n",
      "     0     0 3.0217e+09    0    5 3.0227e+09 3.0217e+09  0.03%     -  698s\n",
      "     0     0 3.0217e+09    0    5 3.0227e+09 3.0217e+09  0.03%     -  699s\n",
      "     0     0 3.0217e+09    0    5 3.0227e+09 3.0217e+09  0.03%     -  700s\n",
      "     0     0 3.0217e+09    0    5 3.0227e+09 3.0217e+09  0.03%     -  702s\n",
      "     0     0 3.0217e+09    0    5 3.0227e+09 3.0217e+09  0.03%     -  703s\n",
      "     0     0 3.0217e+09    0    5 3.0227e+09 3.0217e+09  0.03%     -  704s\n",
      "     0     0 3.0217e+09    0    5 3.0227e+09 3.0217e+09  0.03%     -  705s\n",
      "     0     0 3.0217e+09    0    5 3.0227e+09 3.0217e+09  0.03%     -  706s\n",
      "     0     0 3.0217e+09    0    5 3.0227e+09 3.0217e+09  0.03%     -  708s\n",
      "     0     0 3.0217e+09    0    5 3.0227e+09 3.0217e+09  0.03%     -  709s\n",
      "     0     0 3.0217e+09    0    5 3.0227e+09 3.0217e+09  0.03%     -  710s\n",
      "     0     0 3.0217e+09    0    5 3.0227e+09 3.0217e+09  0.03%     -  711s\n",
      "     0     0 3.0217e+09    0    5 3.0227e+09 3.0217e+09  0.03%     -  712s\n",
      "     0     0 3.0217e+09    0    5 3.0227e+09 3.0217e+09  0.03%     -  714s\n",
      "     0     0 3.0217e+09    0    5 3.0227e+09 3.0217e+09  0.03%     -  715s\n",
      "     0     0 3.0217e+09    0    5 3.0227e+09 3.0217e+09  0.03%     -  716s\n",
      "     0     0 3.0217e+09    0    5 3.0227e+09 3.0217e+09  0.03%     -  718s\n",
      "     0     0 3.0217e+09    0    5 3.0227e+09 3.0217e+09  0.03%     -  719s\n",
      "     0     0 3.0217e+09    0    5 3.0227e+09 3.0217e+09  0.03%     -  720s\n",
      "     0     0 3.0217e+09    0    5 3.0227e+09 3.0217e+09  0.03%     -  722s\n",
      "     0     0 3.0218e+09    0    5 3.0227e+09 3.0218e+09  0.03%     -  723s\n",
      "     0     0 3.0218e+09    0    5 3.0227e+09 3.0218e+09  0.03%     -  725s\n",
      "     0     0 3.0218e+09    0    5 3.0227e+09 3.0218e+09  0.03%     -  726s\n",
      "     0     0 3.0218e+09    0    5 3.0227e+09 3.0218e+09  0.03%     -  727s\n",
      "     0     0 3.0218e+09    0    5 3.0227e+09 3.0218e+09  0.03%     -  729s\n",
      "     0     0 3.0218e+09    0    5 3.0227e+09 3.0218e+09  0.03%     -  730s\n",
      "     0     0 3.0218e+09    0    5 3.0227e+09 3.0218e+09  0.03%     -  731s\n",
      "     0     0 3.0218e+09    0    5 3.0227e+09 3.0218e+09  0.03%     -  732s\n",
      "     0     0 3.0218e+09    0    5 3.0227e+09 3.0218e+09  0.03%     -  733s\n",
      "     0     0 3.0218e+09    0    5 3.0227e+09 3.0218e+09  0.03%     -  735s\n",
      "     0     0 3.0218e+09    0    5 3.0227e+09 3.0218e+09  0.03%     -  736s\n",
      "     0     0 3.0218e+09    0    5 3.0227e+09 3.0218e+09  0.03%     -  737s\n",
      "     0     0 3.0218e+09    0    5 3.0227e+09 3.0218e+09  0.03%     -  738s\n",
      "     0     0 3.0218e+09    0    5 3.0227e+09 3.0218e+09  0.03%     -  742s\n",
      "     0     0 3.0218e+09    0    5 3.0227e+09 3.0218e+09  0.03%     -  746s\n",
      "     0     0 3.0218e+09    0    6 3.0227e+09 3.0218e+09  0.03%     -  748s\n",
      "     0     0 3.0218e+09    0    6 3.0227e+09 3.0218e+09  0.03%     -  750s\n",
      "     0     0 3.0218e+09    0    6 3.0227e+09 3.0218e+09  0.03%     -  752s\n",
      "     0     0 3.0218e+09    0    6 3.0227e+09 3.0218e+09  0.03%     -  753s\n",
      "     0     0 3.0218e+09    0    5 3.0227e+09 3.0218e+09  0.03%     -  755s\n",
      "     0     0 3.0218e+09    0    6 3.0227e+09 3.0218e+09  0.03%     -  757s\n",
      "     0     0 3.0218e+09    0    6 3.0227e+09 3.0218e+09  0.03%     -  759s\n",
      "     0     0 3.0218e+09    0    6 3.0227e+09 3.0218e+09  0.03%     -  760s\n",
      "     0     0 3.0218e+09    0    6 3.0227e+09 3.0218e+09  0.03%     -  762s\n",
      "     0     0 3.0218e+09    0    6 3.0227e+09 3.0218e+09  0.03%     -  764s\n",
      "     0     0 3.0218e+09    0    6 3.0227e+09 3.0218e+09  0.03%     -  765s\n",
      "     0     0 3.0218e+09    0    8 3.0227e+09 3.0218e+09  0.03%     -  785s\n",
      "     0     0 3.0218e+09    0    6 3.0227e+09 3.0218e+09  0.03%     -  789s\n",
      "     0     0 3.0218e+09    0    7 3.0227e+09 3.0218e+09  0.03%     -  791s\n",
      "     0     0 3.0218e+09    0    8 3.0227e+09 3.0218e+09  0.03%     -  812s\n",
      "     0     0 3.0218e+09    0    9 3.0227e+09 3.0218e+09  0.03%     -  817s\n",
      "     0     0 3.0218e+09    0    9 3.0227e+09 3.0218e+09  0.03%     -  819s\n",
      "     0     0 3.0218e+09    0    8 3.0227e+09 3.0218e+09  0.03%     -  822s\n",
      "     0     0 3.0218e+09    0    9 3.0227e+09 3.0218e+09  0.03%     -  824s\n",
      "     0     0 3.0218e+09    0    9 3.0227e+09 3.0218e+09  0.03%     -  827s\n",
      "     0     0 3.0218e+09    0    8 3.0227e+09 3.0218e+09  0.03%     -  833s\n",
      "     0     0 3.0218e+09    0    9 3.0227e+09 3.0218e+09  0.03%     -  837s\n",
      "     0     0 3.0218e+09    0    8 3.0227e+09 3.0218e+09  0.03%     -  840s\n",
      "     0     0 3.0218e+09    0    9 3.0227e+09 3.0218e+09  0.03%     -  843s\n",
      "     0     0 3.0218e+09    0    9 3.0227e+09 3.0218e+09  0.03%     -  845s\n",
      "     0     0 3.0218e+09    0    7 3.0227e+09 3.0218e+09  0.03%     -  847s\n",
      "     0     0 3.0218e+09    0    9 3.0227e+09 3.0218e+09  0.03%     -  850s\n",
      "     0     0 3.0218e+09    0    8 3.0227e+09 3.0218e+09  0.03%     -  856s\n",
      "     0     0 3.0218e+09    0    7 3.0227e+09 3.0218e+09  0.03%     -  861s\n",
      "     0     0 3.0218e+09    0    9 3.0227e+09 3.0218e+09  0.03%     -  866s\n",
      "     0     0 3.0218e+09    0    8 3.0227e+09 3.0218e+09  0.03%     -  870s\n",
      "     0     0 3.0218e+09    0    8 3.0227e+09 3.0218e+09  0.03%     -  873s\n",
      "     0     0 3.0218e+09    0    9 3.0227e+09 3.0218e+09  0.03%     -  875s\n",
      "     0     0 3.0218e+09    0    9 3.0227e+09 3.0218e+09  0.03%     -  881s\n",
      "     0     0 3.0218e+09    0    9 3.0227e+09 3.0218e+09  0.03%     -  889s\n",
      "     0     2 3.0218e+09    0    9 3.0227e+09 3.0218e+09  0.03%     -  897s\n",
      "     1     5 3.0221e+09    1    5 3.0227e+09 3.0218e+09  0.03%   307  902s\n",
      "     3     6 3.0221e+09    2    5 3.0227e+09 3.0218e+09  0.03%   153  905s\n",
      "     9    12 3.0221e+09    5    4 3.0227e+09 3.0218e+09  0.03%  90.7  911s\n",
      "    14    18 3.0221e+09    7    3 3.0227e+09 3.0218e+09  0.03%  65.6  915s\n",
      "    22    28 3.0221e+09   11    3 3.0227e+09 3.0218e+09  0.03%  47.9  922s\n",
      "    27    38 3.0221e+09   13    2 3.0227e+09 3.0218e+09  0.03%  44.2  928s\n",
      "    37    51 3.0221e+09   19    1 3.0227e+09 3.0218e+09  0.03%  38.1  937s\n",
      "    51    73 3.0221e+09   24    1 3.0227e+09 3.0218e+09  0.03%  32.0  947s\n",
      "H   66    73                    3.021878e+09 3.0218e+09  0.00%  26.6  947s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 1\n",
      "  MIR: 157\n",
      "  RLT: 9\n",
      "\n",
      "Explored 74 nodes (2438 simplex iterations) in 948.25 seconds\n",
      "Thread count was 4 (of 4 available processors)\n",
      "\n",
      "Solution count 4: 3.02188e+09 3.0227e+09 3.03851e+09 8.13209e+09 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.021878036400e+09, best bound 3.021798666627e+09, gap 0.0026%\n"
     ]
    }
   ],
   "source": [
    "#setting up model and solving\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "m = gp.Model(\"coal\")\n",
    "\n",
    "#vars\n",
    "s = m.addMVar(solarcnum, lb=0,ub=1, vtype=GRB.BINARY, name=solarnames) #indicator var for if site is built\n",
    "w = m.addMVar(windcnum, lb=0,ub=1, vtype=GRB.BINARY, name=windnames)\n",
    "slack = m.addMVar(h, lb=0, ub=6950, vtype=GRB.CONTINUOUS, name=slacknames)\n",
    "#power = m.addMVar(h, lb=0, ub=GRB.INFINITY, vtype=GRB.CONTINUOUS, name=xsnames)\n",
    "#hours = m.addMVar(h, lb=0, ub=1, vtype=GRB.BINARY, name=hournames[0:h])\n",
    "\n",
    "#for continuous model\n",
    "#s = m.addMVar(solarcnum, lb=0,ub=610, vtype=GRB.CONTINUOUS, name=solarnames)\n",
    "#w = m.addMVar(windcnum, lb=0,ub=630, vtype=GRB.CONTINUOUS, name=windnames)\n",
    "\n",
    "#objective\n",
    "m.setObjective((solarcost @ s) + (windcost @ w), GRB.MINIMIZE)\n",
    "\n",
    "#constraints\n",
    "for hour in range(h):\n",
    "    m.addConstr((solarpower[hour,:] @ s) + (windpower[hour,:] @ w) >= coalhours[hour] - slack[hour])\n",
    "    #m.addConstr((solarpower[hour,:] @ s) + (windpower[hour,:] @ w) >= coalhours[hour] - hours[hour]*6950)\n",
    "m.addConstr(sum(slack) <= 0.1*coaltotal) #allow % of total coal demand to be slacked\n",
    "#m.addConstr(sum(hours) >= 0.7*17520) #if you want to meet certain percent of hours\n",
    "\n",
    "#this is to make linear sites be above certain threshold (ur not gonna make tiny sites)\n",
    "#for site in range(solarcnum):\n",
    "#    m.addConstr(or_(s[site] == 0,s[site] >= slowbound),\"orconstr\")\n",
    "#for site in range(windcnum):\n",
    "#    m.addConstr(or_(w[site] == 0,w[site] >= wlowbound),\"orconstr\")\n",
    "\n",
    "\n",
    "#optimizingc\n",
    "#m.Params.MIPGap = 10**(-6)\n",
    "m.optimize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solar sites used: 44\n",
      "Wind sites used: 79\n",
      "Percent of Hours slacked: 0.322983\n",
      "Percent of Load slacked: 0.0999992\n",
      "Obj (Billion): 3.02188\n",
      "Build Cost (Billion) 3.02188\n"
     ]
    }
   ],
   "source": [
    "#investigating model and reporting results\n",
    "#h = len(coalhours)\n",
    "slackedhours = 0 #how many hours did we not meet (significantly i.e. more than 1% off)\n",
    "slacksum = 0 #how much total load did we not meet\n",
    "powersum = 0\n",
    "slackout = []\n",
    "solarout = []\n",
    "windout = []\n",
    "smallsites = 0\n",
    "\n",
    "for v in m.getVars():\n",
    "    if v.x > 0.01:\n",
    "        name = v.varName\n",
    "        if 'Wind' in name:\n",
    "            windout.append(name)\n",
    "            if v.x < 1:\n",
    "                smallsites += 1\n",
    "            \n",
    "        elif 'Solar' in name:\n",
    "            solarout.append(name)\n",
    "            if v.x < 1:\n",
    "                smallsites += 1\n",
    "        elif 'Slack' in name:\n",
    "            slackedhours += 1\n",
    "            slacksum += v.x\n",
    "            [nada,hour] = name.split(':')\n",
    "            slackout.append(int(hour))\n",
    "        else:\n",
    "            powersum += v.x\n",
    "\n",
    "sint = [round(val) for val in s.x] \n",
    "wint = [round(val) for val in w.x]\n",
    "sitecost = np.matmul(solarcost,sint) + np.matmul(windcost,wint)\n",
    "#coaltotalcost = sum(slack.x)*coalcost\n",
    "solarpowerout = np.matmul(solarpower,sint)\n",
    "windpowerout = np.matmul(windpower,wint)\n",
    "powerout = solarpowerout + windpowerout\n",
    "#energyrevenue = np.matmul(energyprice['HB_HUBAVG'],powerout)\n",
    "#profit = energyrevenue - sitecost\n",
    "    \n",
    "print('Solar sites used: %g' % len(solarout))\n",
    "print('Wind sites used: %g' % len(windout))\n",
    "print('Percent of Hours slacked: %g' % (slackedhours/h))\n",
    "print('Percent of Load slacked: %g' % (slacksum / coaltotal))\n",
    "#print('Obj (Billion): %g' % (m.objVal  / 10**9))\n",
    "print('Build Cost (Billion) %g' % (sitecost / 10**9))\n",
    "#print('Revenue (Billion) %g' % (energyrevenue / 10**9))\n",
    "\n",
    "#saving site output\n",
    "#pd.DataFrame(data={'Solar': solarpowerout, 'Wind': windpowerout}).to_csv('PowerGIS.csv')\n",
    "\n",
    "#saving solver info\n",
    "#m.write('out.mst')\n",
    "#m.write('out.attr')\n",
    "#m.write('out.mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = (sitecost*3) / (sum(powerout))\n",
    "print(mc)\n",
    "pdat = pd.read_csv('Power90.csv')\n",
    "modelpower = pdat['Solar'].to_numpy() + pdat['Wind'].to_numpy()\n",
    "dif = modelpower - coalhours\n",
    "surplus = 0; slack = 0;\n",
    "for d in dif:\n",
    "    if d > 0:\n",
    "        surplus += d\n",
    "    else:\n",
    "        slack += abs(d)\n",
    "print(surplus / (3*10**3),slack / (3*10**3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solarmodel = defaultdict(float)\n",
    "windmodel = defaultdict(float)\n",
    "for site in solarout:\n",
    "    [county,cap] = site.split(' Solar: ')\n",
    "    solarmodel[county] += float(cap)\n",
    "for site in windout:\n",
    "    [county,cap] = site.split(' Wind: ')\n",
    "    windmodel[county] += float(cap)\n",
    "    \n",
    "#model power output save (all 3 years - each half hour - of solar and wind output seperatley\n",
    "pd.DataFrame(data={'Solar': solarpowerout, 'Wind': windpowerout}).to_csv('PowerOut.csv')\n",
    "pd.DataFrame(data={'Slack': slack.x}).to_csv('SlackOut.csv')\n",
    "\n",
    "pd.DataFrame(data=solarmodel,index=['Capacities']).to_csv('SolarOutSites.csv')\n",
    "pd.DataFrame(data=windmodel,index=['Capacities']).to_csv('WindOutSites.csv')\n",
    "pd.DataFrame(data={'Sites': solarout}).to_csv('SitesS.csv')\n",
    "pd.DataFrame(data={'Sites': windout}).to_csv('SitesW.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution\n",
    "coalcap = 14225\n",
    "#coal = pd.read_csv('Coal2019.csv',usecols=['Coal']).to_numpy().flatten()\n",
    "#coal = np.flip(np.sort(2*coal))\n",
    "#coalcf = coal / coalcap\n",
    "\n",
    "pdat = pd.read_csv('Power90.csv')\n",
    "solarp = 2*pdat['Solar'].to_numpy()\n",
    "windp = 2*pdat['Wind'].to_numpy()\n",
    "power = solarp + windp\n",
    "\n",
    "# y = 17520\n",
    "# syear1 = solarp[0:y]\n",
    "# syear2 = solarp[y:2*y]\n",
    "# syear3 = solarp[2*y:3*y]\n",
    "# wyear1 = windp[0:y]\n",
    "# wyear2 = windp[y:2*y]\n",
    "# wyear3 = windp[2*y:3*y]\n",
    "# ayear1 = power[0:y]\n",
    "# ayear2 = power[y:2*y]\n",
    "# ayear3 = power[2*y:3*y]\n",
    "\n",
    "solarcap = 11706.08\n",
    "windcap = 16611.35\n",
    "totalcap = solarcap + windcap\n",
    "\n",
    "# spd1 = np.flip(np.sort(syear1 / spoweravg))\n",
    "# spd2 = np.flip(np.sort(syear2 / spoweravg))\n",
    "# spd3 = np.flip(np.sort(syear3 / spoweravg))\n",
    "# wpd1 = np.flip(np.sort(wyear1 / wpoweravg))\n",
    "# wpd2 = np.flip(np.sort(wyear2 / wpoweravg))\n",
    "# wpd3 = np.flip(np.sort(wyear3 / wpoweravg))\n",
    "# apd1 = np.flip(np.sort(ayear1 / apoweravg))\n",
    "# apd2 = np.flip(np.sort(ayear2 / apoweravg))\n",
    "# apd3 = np.flip(np.sort(ayear3 / apoweravg))\n",
    "\n",
    "solarp = np.flip(np.sort(solarp / solarcap))\n",
    "windp = np.flip(np.sort(windp / windcap))\n",
    "power = np.flip(np.sort(power / totalcap))\n",
    "\n",
    "#yeardic = {'Solar 2009': spd1, 'Solar 2010': spd2, 'Solar 2011': spd3, 'Wind 2009': wpd1, 'Wind 2010': wpd2, 'Wind 2011': wpd3, 'Both 2009': apd1, 'Both 2010': apd2, 'Both 2011': apd3}\n",
    "alldic = {'Solar': solarp, 'Wind': windp, 'Both': power}\n",
    "\n",
    "#pd.DataFrame(data={'Coal Dist': coalyear}).to_csv('CoalDistrYear.csv')\n",
    "#pd.DataFrame(data={'Coal Dist': coalall}).to_csv('CoalDistrExtended.csv')\n",
    "#pd.DataFrame(data=yeardic).to_csv('ModelDistrYears.csv')\n",
    "pd.DataFrame(data=alldic).to_csv('ModelDistr.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monthly average Capacity Factor graph for each fuel type\n",
    "solarpoweragg = np.sum(solarpower,axis=1) #/ 213 #213 counties\n",
    "windpoweragg = np.sum(windpower,axis=1) #/ 213\n",
    "\n",
    "coal = 'Coal2019.csv'\n",
    "coalhours = pd.read_csv(coal,usecols=['Coal']).to_numpy()\n",
    "\n",
    "solaryear = np.empty(17520)\n",
    "windyear = np.empty(17520)\n",
    "for i in range(17520):\n",
    "    solaryear[i] = sum(solarpoweragg[i::17520])/3\n",
    "    windyear[i] = sum(windpoweragg[i::17520])/3\n",
    "\n",
    "solaryear = 2*solaryear / sum(solarcaps)\n",
    "windyear = 2*windyear / sum(windcaps)\n",
    "coalhours = 2*coalhours / 15065\n",
    "days = [31,28,31,30,31,30,31,31,30,31,30,31]\n",
    "d=0\n",
    "\n",
    "sma = np.empty(12); wma = np.empty(12); cma = np.empty(12);\n",
    "for month in range(12):\n",
    "        sma[month] = sum(solaryear[(d*48):((d+days[month])*48)]) / (days[month]*48)\n",
    "        wma[month] = sum(windyear[(d*48):((d+days[month])*48)]) / (days[month]*48)\n",
    "        cma[month] = sum(coalhours[(d*48):((d+days[month])*48)]) / (days[month]*48) #coal max = 6950\n",
    "        d += days[month]\n",
    "\n",
    "'''\n",
    "#same graph for each region\n",
    "smregs = {}\n",
    "wmregs = {}\n",
    "cmregs = {}\n",
    "\n",
    "for reg in regions:\n",
    "    sm = np.empty(12)\n",
    "    wm = np.empty(12)\n",
    "    cm = np.empty(12)\n",
    "    d = 0\n",
    "    \n",
    "    solar3year = solarregcf[reg]\n",
    "    wind3year = windregcf[reg]\n",
    "    solaryear = np.empty(17520)\n",
    "    windyear = np.empty(17520)\n",
    "    for i in range(17520):\n",
    "        solaryear[i] = sum(solar3year[i::17520])/3\n",
    "        windyear[i] = sum(wind3year[i::17520])/3\n",
    "    coalregpower = coalregscf[reg]\n",
    "    \n",
    "    for month in range(12):\n",
    "        sm[month] = sum(solaryear[(d*48):((d+days[month])*48)]) / (days[month]*48)\n",
    "        wm[month] = sum(windyear[(d*48):((d+days[month])*48)]) / (days[month]*48)\n",
    "        cm[month] = sum(coalregpower[(d*24):((d+days[month])*24)]) / (days[month]*24*1) #coal max = 6950\n",
    "        d += days[month]\n",
    "    smregs[reg] = sm\n",
    "    wmregs[reg] = wm\n",
    "    cmregs[reg] = cm\n",
    "''' \n",
    "smregs = {'Solar': sma}\n",
    "wmregs = {'Wind': wma}\n",
    "cmregs = {'Coal': cma}\n",
    "pd.DataFrame(data=smregs).to_csv('SolarMonthlyCF.csv')\n",
    "pd.DataFrame(data=wmregs).to_csv('WindMonthlyCF.csv')\n",
    "pd.DataFrame(data=cmregs).to_csv('CoalMonthlyCF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 17520; a=0*y;b=1*y;\n",
    "pdat = pd.read_csv('PowerGIS.csv')\n",
    "gispower = pdat['Solar'].to_numpy() + pdat['Wind'].to_numpy()\n",
    "gispower = 2*gispower[a:b]\n",
    "pdat = pd.read_csv('Power90.csv')\n",
    "modelpower = pdat['Solar'].to_numpy() + pdat['Wind'].to_numpy()\n",
    "modelpower = 2*modelpower[a:b]\n",
    "pdat = pd.read_csv('Coal2019.csv')\n",
    "coalpower = 2*pdat['Coal'].to_numpy()\n",
    "\n",
    "gisday = np.empty(48)\n",
    "modelday = np.empty(48)\n",
    "coalday = np.empty(48)\n",
    "\n",
    "for h in range(48):\n",
    "    gisday[h] = sum(gispower[h::48]) / 365\n",
    "    modelday[h] = sum(modelpower[h::48]) / 365\n",
    "    coalday[h] = sum(coalpower[h::48]) / 365\n",
    "\n",
    "pd.DataFrame(data={'GIS 2009': gisday, 'Model 2009': modelday, 'Coal': coalday}).to_excel('Day.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep1 = pd.read_csv('EnergyPriceAgg.csv').to_numpy()\n",
    "print(np.max(ep1,0))\n",
    "ep1 = np.sum(ep1[:, 2:5],1) / 3\n",
    "epday = np.empty(48)\n",
    "for h in range(48):\n",
    "    epday[h] = sum(ep1[h::48]) / 365\n",
    "print(sum(epday[16:38]) / 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-38-2eb4cdb9dc2a>:70: RuntimeWarning: invalid value encountered in true_divide\n",
      "  windregcf[reg] = 2*windregout[reg] / windregcap[reg]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nregsurplus = {}\\nregloss = {}\\ngridsurplus = np.zeros(n)\\ngridloss = np.zeros(n)\\nfor reg in regions:\\n    dif = solarregout[reg] + windregout[reg] - coalregs[reg]\\n    surplus = dif.clip(min=0)\\n    loss = (-1*dif).clip(min=0)\\n    regsurplus[reg] = surplus\\n    regloss[reg] = loss\\n    gridsurplus  = gridsurplus + surplus\\n    gridloss = gridloss + loss\\n    \\ntransmission = np.zeros(n)\\nfor h in range(n):\\n    if gridloss[h] > 0:\\n        transmission[h] = min(gridloss[h],gridsurplus[h]) #don't send more than u need, can only send what you have\\ntransday = np.zeros(24)        \\nfor h in range(24):\\n    transday[h] = sum(transmission[h::24]) / (365*3)\\n\\npd.DataFrame(data={'Transmission Req': transday}).to_csv('Transmission.csv')\\n\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting regional info\n",
    "\n",
    "y = 17520\n",
    "n = 3*y\n",
    "solarregout = dict.fromkeys(regions,np.zeros(y)) #every half-hour\n",
    "solarregcap = dict.fromkeys(regions,0)\n",
    "windregout = dict.fromkeys(regions,np.zeros(y))\n",
    "windregcap = dict.fromkeys(regions,0)\n",
    "\n",
    "#if you want to analyze all GIS sites use this\n",
    "solarout = solarnames\n",
    "windout = windnames\n",
    "\n",
    "#if you want to analyze only 90% model sites use this\n",
    "# pdat = pd.read_excel('Sites90.xlsx',sheet_name='SitesLong')\n",
    "# solarout = pdat['Solar'].dropna().to_list()\n",
    "# windout = pdat['Wind'].dropna().to_list()\n",
    "\n",
    "#to compare regional load to power\n",
    "# solarloadout = dict.fromkeys(loadzones,np.zeros(y))\n",
    "# windloadout = dict.fromkeys(loadzones,np.zeros(y))\n",
    "\n",
    "#to look at revenue,cost,profit\n",
    "solarprofit = np.zeros(262)\n",
    "windprofit = np.zeros(108)\n",
    "\n",
    "for site in solarout:\n",
    "    i = solarnames.index(site)\n",
    "    sitepower = solarpower[:,i]\n",
    "    cap = solarcaps[i]\n",
    "    county = solarcounts[i]\n",
    "    reg = simpregdict[county]\n",
    "    avpower = (sitepower[0:y] + sitepower[y:(2*y)] + sitepower[(2*y):(3*y)])/3\n",
    "    solarregout[reg] = solarregout[reg] + avpower #((sitepower[::2] + sitepower[1::2]) / 1) #divide by 2 b/c want avg power (if MWh don't)\n",
    "    solarregcap[reg] = solarregcap[reg] + cap\n",
    "\n",
    "    #if you want to compare regional load to power\n",
    "#     avpower = (sitepower[0:y] + sitepower[y:(2*y)] + sitepower[(2*y):(3*y)])/3\n",
    "#     cost = solarcost[i]\n",
    "#     loadreg = weathertoload[reg]\n",
    "#     solarloadout[loadreg] = solarloadout[loadreg] + avpower\n",
    "    #if you want to look at revenue,cost,profit\n",
    "#     rev = np.matmul(energyprice[loadreg],avpower)\n",
    "#     solarprofit[i] = (rev - cost) #annual\n",
    "    \n",
    "for site in windout:\n",
    "    i = windnames.index(site)\n",
    "    sitepower = windpower[:,i]\n",
    "    cap = windcaps[i]\n",
    "    county = windcounts[i]\n",
    "    reg = simpregdict[county]\n",
    "    avpower = (sitepower[0:y] + sitepower[y:(2*y)] + sitepower[(2*y):(3*y)])/3\n",
    "    windregout[reg] = windregout[reg] + avpower\n",
    "    windregcap[reg] = windregcap[reg] + cap\n",
    "    \n",
    "    #if you want to compare regional load to power\n",
    "#     avpower = (sitepower[0:y] + sitepower[y:(2*y)] + sitepower[(2*y):(3*y)])/3\n",
    "#     cost = windcost[i]\n",
    "#     loadreg = weathertoload[reg]\n",
    "#     windloadout[loadreg] = windloadout[loadreg] + avpower\n",
    "    #if you want to look at revenue,cost,profit\n",
    "#     rev = np.matmul(energyprice[loadreg],avpower)\n",
    "#     windprofit[i] = (rev - cost) #annual\n",
    "    \n",
    "solarregcf = {}\n",
    "windregcf = {}\n",
    "regcap = {}\n",
    "for reg in regions:\n",
    "    solarregcf[reg] = 2*solarregout[reg] / solarregcap[reg]\n",
    "    windregcf[reg] = 2*windregout[reg] / windregcap[reg]\n",
    "    regcap[reg] = [solarregcap[reg],windregcap[reg]]    \n",
    "#pd.DataFrame(data=regcap).to_csv('RegOut.csv')\n",
    "\n",
    "solarregsday = {}\n",
    "windregsday = {}\n",
    "bothregsday = {}\n",
    "coalregsday = {}\n",
    "\n",
    "# mi = 8688\n",
    "# mf = 10176\n",
    "# for reg in regions:\n",
    "#     solarregpower = solarregcf[reg] #getting average capacity factor in region\n",
    "#     windregpower = windregcf[reg]\n",
    "#     #coalregpower = coalregscf[reg]\n",
    "#     solarday = np.empty(48)\n",
    "#     windday = np.empty(48)\n",
    "#     coalday = np.empty(24)\n",
    "#     for h in range(48):\n",
    "#         solarday[h] = sum(solarregpower[mi+h:mf:48] + solarregpower[mi+h+y:mf+y:48] + solarregpower[mi+h+(2*y):mf+(2*y):48]) / (31*3)\n",
    "#         windday[h] = sum(windregpower[mi+h:mf:48] + windregpower[mi+h+y:mf+y:48] + windregpower[mi+h+(2*y):mf+(2*y):48]) / (31*3)\n",
    "#     #for h in range(24):\n",
    "#         #coalday[h] = sum(coalregpower[h:744:24]) / 31\n",
    "#     solarregsday[reg] = solarday\n",
    "#     windregsday[reg] = windday\n",
    "#     #bothregsday[reg] = solarday + windday\n",
    "#     #coalregsday[reg] = coalday\n",
    "    \n",
    "#pd.DataFrame(data=solarregsday).to_csv('SolarRegionsJul.csv')\n",
    "#pd.DataFrame(data=windregsday).to_csv('WindRegionsJul.csv')\n",
    "#pd.DataFrame(data=bothregsday).to_csv('ModelRegions.csv')\n",
    "#pd.DataFrame(data=coalregsday).to_csv('CoalRegions.csv')\n",
    "\n",
    "\n",
    "#looking hourly surpluses/losses within each region and grid tranmission \n",
    "#simplistic case where any sort of cross regions transmission is just transmission\n",
    "#- a more realistic case would consider it easier to transmit to neighbours\n",
    "'''\n",
    "regsurplus = {}\n",
    "regloss = {}\n",
    "gridsurplus = np.zeros(n)\n",
    "gridloss = np.zeros(n)\n",
    "for reg in regions:\n",
    "    dif = solarregout[reg] + windregout[reg] - coalregs[reg]\n",
    "    surplus = dif.clip(min=0)\n",
    "    loss = (-1*dif).clip(min=0)\n",
    "    regsurplus[reg] = surplus\n",
    "    regloss[reg] = loss\n",
    "    gridsurplus  = gridsurplus + surplus\n",
    "    gridloss = gridloss + loss\n",
    "    \n",
    "transmission = np.zeros(n)\n",
    "for h in range(n):\n",
    "    if gridloss[h] > 0:\n",
    "        transmission[h] = min(gridloss[h],gridsurplus[h]) #don't send more than u need, can only send what you have\n",
    "transday = np.zeros(24)        \n",
    "for h in range(24):\n",
    "    transday[h] = sum(transmission[h::24]) / (365*3)\n",
    "\n",
    "pd.DataFrame(data={'Transmission Req': transday}).to_csv('Transmission.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monthly regional capacity factor\n",
    "days = np.array([31,28,31,30,31,30,31,31,30,31,30,31]); halfhours = days*48; hsums = []\n",
    "for month in range(12):\n",
    "    hsums.append(sum(halfhours[:month]))\n",
    "hsums.append(17520)\n",
    "months = ['January','February','March','April','May','June','July','August','September','October','November','December']\n",
    "\n",
    "smregs = {}\n",
    "wmregs = {}\n",
    "cmregs = {}\n",
    "\n",
    "targetregs = ['NORTH','COAST','SOUTH','FWEST']\n",
    "for month in range(12):\n",
    "    outdic = {}\n",
    "    for reg in targetregs:\n",
    "        solaryear = solarregcf[reg]\n",
    "        windyear = windregcf[reg]\n",
    "        solarmonth = solaryear[hsums[month]:hsums[month+1]]\n",
    "        windmonth = windyear[hsums[month]:hsums[month+1]]\n",
    "        solarday = np.empty(48)\n",
    "        windday = np.empty(48)\n",
    "        for hh in range(48):\n",
    "            solarday[hh] = sum(solarmonth[hh::48]) / days[month]\n",
    "            windday[hh] = sum(windmonth[hh::48]) / days[month]\n",
    "        outdic[reg + 'Solar'] = solarday\n",
    "        outdic[reg + 'Wind'] = windday\n",
    "    pd.DataFrame(data=outdic).to_csv('AA'+months[month]+'.csv')\n",
    "        \n",
    "# pd.DataFrame(data=smregs).to_csv('SolarMonthlyCF.csv')\n",
    "# pd.DataFrame(data=wmregs).to_csv('WindMonthlyCF.csv')\n",
    "# pd.DataFrame(data=cmregs).to_csv('CoalMonthlyCF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regsums = {}\n",
    "totals = [0,0,0]\n",
    "print(regions)\n",
    "for reg in regions:\n",
    "    regsums[reg] = [sum(solarregout[reg])/(3*1000),sum(windregout[reg])/(3*1000),sum(coalregs[reg])/1000]\n",
    "    totals[0] += sum(solarregout[reg])/(3*1000); totals[1] += sum(windregout[reg])/(3*1000)\n",
    "    totals[2] += sum(coalregs[reg])/1000\n",
    "revd = 0\n",
    "powerall = np.zeros(17520)\n",
    "for reg in loadzones:\n",
    "    regpower = solarloadout[reg]+windloadout[reg]\n",
    "    revd += np.matmul(energyprice[reg],regpower)\n",
    "    print(sum(regpower) / 1000)\n",
    "    powerall += regpower\n",
    "rev = np.matmul(energyprice['HB_HUBAVG'],powerall)\n",
    "revcoal = np.matmul(energyprice['HB_HUBAVG'],coalhours[0:17520])\n",
    "scale = 10**9\n",
    "print(sum(coalhours[0:17520]) / 1000)\n",
    "print(totals)\n",
    "#print(revd / scale, rev / scale, revcoal / scale)\n",
    "#print(regsums)\n",
    "pd.DataFrame(data=regsums).to_csv('RegSumsNew.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing generalizability to other years\n",
    "powertest = np.matmul(solarpowertest,sint) + np.matmul(windpowertest,wint)\n",
    "slacktest = 0 \n",
    "hourtest = 0\n",
    "dif = np.transpose(coalhours[0:17520]) - powertest\n",
    "\n",
    "for i in range(17520):\n",
    "    if dif[i] > 0:\n",
    "        slacktest += dif[i]\n",
    "        hourtest += 1\n",
    "print(1-(slacktest / (coaltotal/2)))\n",
    "print(1-(hourtest / 17520))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#which sites are the most efficient (cost per MW), what range of costs do we have\n",
    "'''\n",
    "coalgwh = coaltotal / (3*10**3)\n",
    "pdat = pd.read_excel('Sites90.xlsx',sheet_name='SitesLong')\n",
    "solarout = pdat['Solar'].dropna().to_list()\n",
    "windout = pdat['Wind'].dropna().to_list()\n",
    "sitesout = pdat['Solar'].dropna().to_list() + pdat['Wind'].to_list()\n",
    "'''\n",
    "#2.81 billion\n",
    "\n",
    "ssum = sum(solarpower) / 3\n",
    "wsum = sum(windpower) / 3\n",
    "seff = solarcost / ssum\n",
    "weff = windcost / wsum\n",
    "#seff = solarprofit / (10**6)\n",
    "#weff = windprofit / (10**6)\n",
    "twine = []\n",
    "\n",
    "for i in range(windcnum):\n",
    "    #twine.append((seff[i],ssum[i],solarnames[i]))\n",
    "    #twine.append((weff[i],wsum[i],windnames[i]))\n",
    "    twine.append((seff[i],solarcost[i],i,solarnames[i], ssum[i]))\n",
    "    twine.append((weff[i],windcost[i],i,windnames[i], wsum[i]))\n",
    "for i in range(windcnum,solarcnum):\n",
    "    #twine.append((seff[i],ssum[i],solarnames[i]))\n",
    "    twine.append((seff[i],solarcost[i],i,solarnames[i], ssum[i]))\n",
    "\n",
    "twine.sort()\n",
    "#twine.reverse() #need to reverse for falling profitability\n",
    "order = []\n",
    "efforder = []\n",
    "sumorder = []\n",
    "\n",
    "fcolor = []\n",
    "totalcost = 0\n",
    "powerpack = np.zeros(52560)\n",
    "for i in range(windcnum+solarcnum):\n",
    "    name = twine[i][3]\n",
    "    idx = twine[i][2]\n",
    "    cost = twine[i][1]\n",
    "    totalcost += cost\n",
    "    if totalcost > 2.81*(10**9):\n",
    "        cur = i\n",
    "        break\n",
    "    order.append(name)\n",
    "    efforder.append(twine[i][0])\n",
    "    #sumorder.append(twine[i][1] / 10**3)\n",
    "    sumorder.append(twine[i][4] / 10**3)\n",
    "    if 'Solar:' in name:\n",
    "        fcolor.append('bisque')\n",
    "        powerpack += solarpower[:,idx]\n",
    "    else:\n",
    "        fcolor.append('lightsteelblue')\n",
    "        powerpack += windpower[:,idx]\n",
    "slack = np.maximum(coalhours - powerpack, np.zeros(52560))\n",
    "slackp = sum(slack) / sum(coalhours)\n",
    "print(slackp)\n",
    "\n",
    "coalday = np.empty(48)\n",
    "cheapday = np.empty(48)\n",
    "slackday = np.empty(48)\n",
    "for h in range(48):\n",
    "    coalday[h] = sum(coalhours[h::48]) / (365*3)\n",
    "    cheapday[h] = sum(powerpack[h::48]) / (365*3)\n",
    "    slackday[h] = sum(slack[h::48]) / (365*3)\n",
    "pd.DataFrame(data={'Coal': coalday,'Cheapest Sites': cheapday, 'Slack': slackday}).to_excel('CheapSites.xlsx')\n",
    "\n",
    "'''\n",
    "for site in sitesout:\n",
    "    i = order.index(site)\n",
    "    if fcolor[i] == 'bisque':\n",
    "        fcolor[i] = 'darkorange'\n",
    "    elif fcolor[i] == 'lightsteelblue':\n",
    "        fcolor[i] = 'blue'\n",
    "\n",
    "sp = 0; sc = 0;\n",
    "wp = 0; wc = 0;\n",
    "\n",
    "for site in solarout:\n",
    "    i = solarnames.index(site)\n",
    "    sp += ssum[i]\n",
    "    sc += solarcost[i]\n",
    "for site in windout:\n",
    "    i = windnames.index(site)\n",
    "    wp += wsum[i]\n",
    "    wc += windcost[i]\n",
    "#print(sp,sc,wp,wc)\n",
    "print((sc+wc) / (sp+wp))\n",
    "'''\n",
    "# popi = []        \n",
    "# for i in range(0,len(sitesout)-1):\n",
    "#     n = i+1\n",
    "#     count = order[i].split(':')[0]\n",
    "#     sc = sumorder[i]\n",
    "#     while count == order[n].split(':')[0]:\n",
    "#         sc += sumorder[n]\n",
    "#         popi.append(n)\n",
    "#         n = n+1\n",
    "#     sumorder[i] = sc\n",
    "        \n",
    "# for i in popi:\n",
    "#     order.pop(i); efforder.pop(i); sumorder.pop(i); fcolor.pop(i);\n",
    "'''\n",
    "xs = np.zeros(solarcnum+windcnum)\n",
    "for i in range(1,solarcnum+windcnum):\n",
    "    xs[i] = xs[i-1] + sumorder[i-1]\n",
    "    if abs(efforder[i]) < 0.2:\n",
    "        efforder[i] += (efforder[i] / (2*abs(efforder[i])))\n",
    "        print(order[i],efforder[i])\n",
    "\n",
    "srange = [min(seff),max(seff)]\n",
    "wrange = [min(weff),max(weff)]\n",
    "print('Solar Price Per MWh Range: %s' % srange)\n",
    "print('Wind Price Per MWh Range: %s' % wrange)\n",
    "'''\n",
    "# for i in range(windcnum):\n",
    "#     sorder.append(stwine[i][1])\n",
    "#     worder.append(wtwine[i][1])\n",
    "# for i in range(windcnum,solarcnum):\n",
    "#     sorder.append(stwine[i][1])\n",
    "\n",
    "# sorder = list(dict.fromkeys(sorder)) #remove repeats\n",
    "# worder = list(dict.fromkeys(worder))\n",
    "# sorder = [count + ' Solar' for count in sorder]\n",
    "# worder = [count + ' Wind' for count in worder]\n",
    "\n",
    "#basically want to see whether its taking greedy 'best' sites or not\n",
    "# sg = defaultdict(float)\n",
    "# wg = defaultdict(float)\n",
    "\n",
    "\n",
    "# for count in solarout:\n",
    "#     [x,y] = count.split(':')\n",
    "#     i = sorder.index(x)\n",
    "#     sg[i+1] += float(y)\n",
    "# for count in windout:\n",
    "#     [x,y] = count.split(':')\n",
    "#     i = worder.index(x)\n",
    "#     wg[i+1] += float(y)\n",
    "\n",
    "# sg = dict(sorted(sg.items()))\n",
    "# wg = dict(sorted(wg.items()))\n",
    "\n",
    "# pd.DataFrame(data=[sg,wg]).to_csv('Eff90Full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator, FuncFormatter\n",
    "import math\n",
    "\n",
    "fig,ax = plt.subplots(1, figsize=(15,3))\n",
    "#plt.grid(zorder=0); ax.set_axisbelow(True)\n",
    "plt.bar(x=xs, height=efforder, width=sumorder, align='edge', color=fcolor)\n",
    "plt.axvline(x=coalgwh,linestyle='--',color='black'); plt.text(coalgwh+1000,40,'Coal GWh')\n",
    "plt.xlabel('Annual Energy Supplied (GWh)'); plt.ylabel('Levelized Cost ($ / MWh)');\n",
    "ax.set_xlim((0,xs[-1]+5000)); \n",
    "ax.xaxis.set_major_locator(MultipleLocator(25000)); #ax.xaxis.set_minor_locator(MultipleLocator(25000))\n",
    "ax.get_xaxis().set_major_formatter(FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(5))\n",
    "ax.spines['bottom'].set_color('gray'); ax.spines['top'].set_color('white');\n",
    "ax.spines['right'].set_color('white'); ax.spines['left'].set_color('gray');\n",
    "\n",
    "lcolors = {'Wind Used':'blue', 'Wind Unused':'lightsteelblue','Solar Used':'darkorange', 'Solar Unused':'bisque'}   \n",
    "lecolors = {'Wind Used':'blue', 'Wind Unused':'lightsteelblue','Solar Used':'darkorange', 'Solar Unused':'bisque'} \n",
    "labels = list(lcolors.keys())\n",
    "handles = [plt.Rectangle((0,0),1,1, facecolor=lcolors[label], edgecolor=lecolors[label]) for label in labels]\n",
    "plt.legend(handles, labels)\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.savefig('Site_Selection_Bar_AnnualProfit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quartiles\n",
    "csv = 'Power90.csv'\n",
    "pdat = pd.read_csv(csv)\n",
    "allpower = 2*(pdat['Solar'].to_numpy() + pdat['Wind'].to_numpy())\n",
    "print(allpower.shape)\n",
    "n = 17520\n",
    "\n",
    "year1 = allpower[0:n].flatten()\n",
    "year2 = allpower[n:(2*n)].flatten()\n",
    "year3 = allpower[(2*n):(3*n)].flatten()\n",
    "\n",
    "day1 = np.empty(48)\n",
    "day2 = np.empty(48)\n",
    "day3 = np.empty(48)\n",
    "jan1 = np.empty(48)\n",
    "jan2 = np.empty(48)\n",
    "jan3 = np.empty(48)\n",
    "jul1 = np.empty(48)\n",
    "jul2 = np.empty(48)\n",
    "jul3 = np.empty(48)\n",
    "#aprall = np.empty(48)\n",
    "#octall = np.empty(48)\n",
    "\n",
    "for i in range(48):\n",
    "    day = np.sort(allpower[i::48])   #(year1[i::48])\n",
    "    day1[i] = (day[273]) #1st quratile ie median of first half (day[90] + day[91])/2\n",
    "    day2[i] = day[547] #2nd quartile ie median (day[182])\n",
    "    day3[i] = day[821]# (day[273] + day[274]) / 2\n",
    "    jan = np.sort(np.hstack((year1[i:1488:48],year2[i:1488:48],year3[i:1488:48])))   #(year1[i:1488:48])\n",
    "    jan1[i] = (jan[22] + jan[23]) / 2 #jan[7]\n",
    "    jan2[i] = jan[46]#jan[15]\n",
    "    jan3[i] = (jan[69] + jan[70]) / 2 #jan[23]\n",
    "    jul = np.sort(np.hstack((year1[8688+i:10176:48],year2[8688+i:10176:48],year3[8688+i:10176:48])))   #(year1[8688+i:10176:48])\n",
    "    jul1[i] = (jul[22] + jul[23]) / 2 #jul[7]\n",
    "    jul2[i] = jul[46] #jul[15]\n",
    "    jul3[i] = (jul[69] + jul[70]) / 2 #jul[23]\n",
    "    #aprall[i] = (sum(year1[4320+i:5760:48]) + sum(year2[4320+i:5760:48]) + sum(year3[4320+i:5760:48])) / (3*30)\n",
    "    #octall[i] = (sum(year1[13104+i:14592:48]) + sum(year2[13104+i:14592:48]) + sum(year3[13104+i:14592:48])) / (3*31)\n",
    "\n",
    "#years = {'2009 Year': year1, '2010 Year': year2, '2011 Year': year3}\n",
    "#alld = {'2009 Day': day1, '2010 Day': day2, '2011 Day': day3}\n",
    "alld = {'Year Q1': day1, 'Year Q2': day2, 'Year Q3': day3}\n",
    "alld['Jan Q1'] = jan1\n",
    "alld['Jan Q2'] = jan2\n",
    "alld['Jan Q3'] = jan3\n",
    "alld['Jul Q1'] = jul1 \n",
    "alld['Jul Q2'] = jul2\n",
    "alld['Jul Q3'] = jul3\n",
    "#aproct = {'April': aprall, 'October': octall}\n",
    "\n",
    "pd.DataFrame(data=alld).to_excel('Model90Qs.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fuel mix info\n",
    "\n",
    "#fuel = 'Fuel2011.xls' \n",
    "#months = ['Jan11','Feb11','Mar11','Apr11','May11','Jun11','Jul11','Aug11','Sep11','Oct11','Nov11','Dec11']\n",
    "fuel = 'Fuel2019.xlsx'\n",
    "months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "xls = pd.ExcelFile(fuel)\n",
    "\n",
    "biomass = np.empty(0)\n",
    "coal = np.empty(0)\n",
    "gas = np.empty(0)\n",
    "gascc = np.empty(0)\n",
    "hydro = np.empty(0)\n",
    "nuclear = np.empty(0)\n",
    "other = np.empty(0)\n",
    "solar = np.empty(0)\n",
    "wind = np.empty(0)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(12):\n",
    "    dat = pd.read_excel(xls, months[i])\n",
    "    \n",
    "    biomassyear = dat.loc[dat['Fuel']==\"Biomass\"]\n",
    "    biomassyear = biomassyear[biomassyear.columns[4::2]].to_numpy() + biomassyear[biomassyear.columns[5::2]].to_numpy()\n",
    "    biomassyear = np.reshape(biomassyear,np.prod(biomassyear.shape))\n",
    "    biomass = np.concatenate((biomass,biomassyear))\n",
    "    \n",
    "    coalyear = dat.loc[dat['Fuel']==\"Coal\"]\n",
    "    coalyear = coalyear[coalyear.columns[4::2]].to_numpy() + coalyear[coalyear.columns[5::2]].to_numpy()\n",
    "    coalyear = np.reshape(coalyear,np.prod(coalyear.shape))\n",
    "    coal = np.concatenate((coal,coalyear))\n",
    "    \n",
    "    gasyear = dat.loc[dat['Fuel']==\"Gas\"]\n",
    "    gasyear = gasyear[gasyear.columns[4::2]].to_numpy() + gasyear[gasyear.columns[5::2]].to_numpy()\n",
    "    gasyear = np.reshape(gasyear,np.prod(gasyear.shape))\n",
    "    gas = np.concatenate((gas,gasyear))\n",
    "\n",
    "    gasccyear = dat.loc[dat['Fuel']==\"Gas-CC\"]\n",
    "    gasccyear = gasccyear[gasccyear.columns[4::2]].to_numpy() + gasccyear[gasccyear.columns[5::2]].to_numpy()\n",
    "    gasccyear = np.reshape(gasccyear,np.prod(gasccyear.shape))\n",
    "    gascc = np.concatenate((gascc,gasccyear))\n",
    "\n",
    "    hydroyear = dat.loc[dat['Fuel']==\"Hydro\"]\n",
    "    hydroyear = hydroyear[hydroyear.columns[4::2]].to_numpy() + hydroyear[hydroyear.columns[5::2]].to_numpy()\n",
    "    hydroyear = np.reshape(hydroyear,np.prod(hydroyear.shape))\n",
    "    hydro = np.concatenate((hydro,hydroyear))\n",
    "    \n",
    "    nuclearyear = dat.loc[dat['Fuel']==\"Nuclear\"]\n",
    "    nuclearyear = nuclearyear[nuclearyear.columns[4::2]].to_numpy() + nuclearyear[nuclearyear.columns[5::2]].to_numpy()\n",
    "    nuclearyear = np.reshape(nuclearyear,np.prod(nuclearyear.shape))\n",
    "    nuclear = np.concatenate((nuclear,nuclearyear))\n",
    "    \n",
    "    otheryear = dat.loc[dat['Fuel']==\"Other\"]\n",
    "    otheryear = otheryear[otheryear.columns[4::2]].to_numpy() + otheryear[otheryear.columns[5::2]].to_numpy()\n",
    "    otheryear = np.reshape(otheryear,np.prod(otheryear.shape))\n",
    "    other = np.concatenate((other,otheryear))\n",
    "\n",
    "    solaryear = dat.loc[dat['Fuel']==\"Solar\"]\n",
    "    solaryear = solaryear[solaryear.columns[4::2]].to_numpy() + solaryear[solaryear.columns[5::2]].to_numpy()\n",
    "    solaryear = np.reshape(solaryear,np.prod(solaryear.shape))\n",
    "    solar = np.concatenate((solar,solaryear))\n",
    "\n",
    "    windyear = dat.loc[dat['Fuel']==\"Wind\"]\n",
    "    windyear = windyear[windyear.columns[4::2]].to_numpy() + windyear[windyear.columns[5::2]].to_numpy()\n",
    "    windyear = np.reshape(windyear,np.prod(windyear.shape))\n",
    "    wind = np.concatenate((wind,windyear))\n",
    "    \n",
    "biomass = np.nan_to_num(biomass)\n",
    "coal = np.nan_to_num(coal) # / (18774/2) # (14297/2)\n",
    "gas = np.nan_to_num(gas) # / (47259/2)\n",
    "gascc = np.nan_to_num(gascc)\n",
    "hydro = np.nan_to_num(hydro)\n",
    "nuclear = np.nan_to_num(nuclear)\n",
    "other = np.nan_to_num(other)\n",
    "solar = np.nan_to_num(solar)\n",
    "wind = np.nan_to_num(wind) # / (9452/2)\n",
    "solar = np.nan_to_num(solar)\n",
    "#solar = pd.read_excel('SolarProfile2011.xlsx',usecols=['Total']).to_numpy().flatten()\n",
    "#solar = solar / max(solar)\n",
    "#oldrenewables = wind+other+hydro\n",
    "#total = coal+gas+nuclear+oldrenewables\n",
    "oldrenewables = solar+wind+other+biomass+hydro\n",
    "total = coal+gas+gascc+nuclear+oldrenewables\n",
    "total3 = np.hstack((total,total,total))\n",
    "\n",
    "pdat = pd.read_csv('Power90.csv')\n",
    "solarp = pdat['Solar'].to_numpy()\n",
    "windp = pdat['Wind'].to_numpy()\n",
    "'''\n",
    "solarpower = np.empty(17520)\n",
    "windpower = np.empty(17520)\n",
    "for i in range(17520):\n",
    "    solarpower[i] = sum(solarp[i::17520])/3\n",
    "    windpower[i] = sum(windp[i::17520])/3\n",
    "    \n",
    "pdat = pd.read_excel('Sites90.xlsx',sheet_name='SitesLong')\n",
    "solarout = pdat['Solar'].dropna().to_list()\n",
    "windout = pdat['Wind'].dropna().to_list()\n",
    "sitesout = pdat['Solar'].dropna().to_list() + pdat['Wind'].to_list()\n",
    "\n",
    "solarmodel = np.zeros(52560)\n",
    "windmodel = np.zeros(52560)\n",
    "sc = 0; wc = 0;\n",
    "\n",
    "for site in solarout:\n",
    "    i = solarnames.index(site)\n",
    "    solarmodel += solarpower[:,i]\n",
    "    cap = float(site.split(': ')[1])\n",
    "    sc += cap\n",
    "for site in windout:\n",
    "    i = windnames.index(site)\n",
    "    windmodel += windpower[:,i]\n",
    "    cap = float(site.split(': ')[1])\n",
    "    wc += cap\n",
    "\n",
    "totalmodel = 2*(solarmodel + windmodel) / (sc+wc)\n",
    "solarmodel = 2*solarmodel / sc\n",
    "windmodel = 2*windmodel / wc\n",
    "\n",
    "gas3 = 2*(gas + gascc) / (19310 + 35564)\n",
    "gas3 = np.hstack((gas3,gas3,gas3))\n",
    "\n",
    "solarmodelh = (solarmodel[::2] + solarmodel[1::2]) / 2\n",
    "windmodelh = (windmodel[::2] + windmodel[1::2]) / 2\n",
    "windh = (wind[::2] + wind[1::2]) / 2\n",
    "coalh = (coal[::2] + coal[1::2]) / 2\n",
    "gash = (gas[::2] + gas[1::2]) / 2\n",
    "print(coalh.shape)\n",
    "'''\n",
    "\n",
    "load2009 = pd.read_excel('2009_ERCOT_Hourly_Load_Data.xls',usecols=['ERCOT']).to_numpy().flatten()\n",
    "load2009 = np.repeat(load2009, 2)\n",
    "load2010 = pd.read_excel('2010_ERCOT_Hourly_Load_Data.xls',usecols=['ERCOT']).to_numpy().flatten()\n",
    "load2010 = np.repeat(load2010, 2)\n",
    "load2011 = pd.read_excel('Native_Load_2011.xls',usecols=['ERCOT']).to_numpy().flatten()\n",
    "load2011 = np.repeat(load2011, 2)\n",
    "load = pd.read_excel('Native_Load_2019.xlsx',usecols=['ERCOT']).to_numpy().flatten()\n",
    "load2019 = np.repeat(load, 2)\n",
    "\n",
    "y = 17520\n",
    "gas2019 = gas + gascc\n",
    "coal2019 = coal\n",
    "outdic = {'Load 2009': load2009,'Load 2010': load2010,'Load 2011': load2011, 'Load 2019': load2019, 'Solar 2009': 2*solarp[0:y],\n",
    "          'Solar 2010': 2*solarp[y:(2*y)], 'Solar 2011': 2*solarp[(2*y):(3*y)], 'Wind 2009': 2*windp[0:y],\n",
    "          'Wind 2010': 2*windp[y:(2*y)], 'Wind 2011': 2*windp[(2*y):(3*y)], 'Coal 2019': 2*coal2019, 'Gas 2019': 2*gas2019}\n",
    "# pd.DataFrame(data = outdic).to_csv('Output_vs_Load.csv')\n",
    "\n",
    "\n",
    "\n",
    "load3 = np.hstack((load,load,load))\n",
    "\n",
    "#oldrenewablesh = oldrenewables[::2] + oldrenewables[1::2]\n",
    "coalh = coal[::2] + coal[1::2]\n",
    "solarp = solarp[::2] + solarp[1::2]\n",
    "windp= windp[::2] + windp[1::2]\n",
    "\n",
    "#oldrenew3 = np.hstack((oldrenewablesh,oldrenewablesh,oldrenewablesh))\n",
    "coal3 = np.hstack((coalh,coalh,coalh))\n",
    "old = load3 - coal3\n",
    "new = load3 - (solarp+windp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slack (based off fuel mix data)\n",
    "dif = coal3 - (solarp+windp)\n",
    "slack = np.empty(52560)\n",
    "for i in range(52560):\n",
    "    slack[i] = max(0,dif[i])\n",
    "\n",
    "difday = np.empty(48)\n",
    "slackday = np.empty(48)\n",
    "s1 = np.empty(48)\n",
    "s2 = np.empty(48)\n",
    "s3 = np.empty(48)\n",
    "\n",
    "#slack quartilers\n",
    "for i in range(48):\n",
    "    sh = np.sort(slack[i::48])\n",
    "    s1[i] = 2*sh[273]\n",
    "    s2[i] = 2*sh[547]\n",
    "    s3[i] = 2*sh[821]\n",
    "    difday[i] = sum(dif[i::48]) / (365*3)\n",
    "    slackday[i] = sum(slack[i::48]) / (365*3)\n",
    "#slack quartiles\n",
    "pd.DataFrame(data={'Slack Q1':s1, 'Slack Q2': s2, 'Slack Q3': s3}).to_csv('SlackQs.csv')\n",
    "#average slack day and difference day\n",
    "pd.DataFrame(data={'Dif':difday, 'Slack': slackday}).to_excel('SlackOut.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.779243436500902 8035.444593707889 1.9653871321836818 10102.21130075584\n"
     ]
    }
   ],
   "source": [
    "#Required Ramping of other energy sources to satisfy load (based off fuel mix and model data)\n",
    "yh = 8760\n",
    "oldavg = sum(old) / (yh*3)\n",
    "newavg = sum(new)/ (yh*3)\n",
    "oldpeak = max(old)\n",
    "newpeak = max(new)\n",
    "oldstd = np.std(old)\n",
    "newstd = np.std(new)\n",
    "print(oldpeak/oldavg,oldstd,newpeak/newavg,newstd)\n",
    "\n",
    "#monthly comparison of old and new required ramping\n",
    "#can easily be done for full year if mi = 0, mf = yh, and days[month] is set to 365\n",
    "outday = {}\n",
    "for month in range(12):\n",
    "    oldday = np.empty(24)\n",
    "    newday = np.empty(24)\n",
    "    mi = hsums[month] // 2 #divide by 2 because half-hours, no rounding errors in division (all will be integers)\n",
    "    mf = hsums[month+1] // 2\n",
    "    for h in range(24):\n",
    "        oldday[h] = sum(old[mi+h:mf:24] + old[mi+h+yh:mf+yh:24] + old[mi+h+(2*yh):mf+(2*yh):24]) / (days[month]*3)\n",
    "        newday[h] = sum(new[mi+h:mf:24] + new[mi+h+yh:mf+yh:24] + new[mi+h+(2*yh):mf+(2*yh):24]) / (days[month]*3)\n",
    "        outday['Old' + months[month]] = oldday\n",
    "        outday['New' + months[month]] = newday\n",
    "\n",
    "#top level analysis\n",
    "olddist = np.flip(np.sort(old / oldavg))\n",
    "newdist = np.flip(np.sort(new / newavg))\n",
    "outlong = {'Old Req':old, 'New Req': new}\n",
    "outdist = {'Old Req Dist':olddist, 'New Req Dist': newdist}\n",
    "\n",
    "#pd.DataFrame(data=outlong).to_excel('RequiredRamping.xlsx')\n",
    "pd.DataFrame(data=outday).to_excel('RequiredRampingSupplement.xlsx')\n",
    "#pd.DataFrame(data=outdist).to_excel('RequiredRamping.xlsx')\n",
    "\n",
    "#plt.plot(new, color='blue')\n",
    "#plt.plot(old, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fuel mix graph\n",
    "bh = np.empty(48); ch = np.empty(48); gh = np.empty(48); gcch = np.empty(48); hh = np.empty(48); nh = np.empty(48);\n",
    "oh = np.empty(48); sh = np.empty(48); wh = np.empty(48); sph = np.empty(48); wph = np.empty(48);\n",
    "\n",
    "mi = 8688 #0\n",
    "mf = 10176 #1488\n",
    "dn = 31\n",
    "\n",
    "for h in range(48):\n",
    "    bh[h] = (2*sum(biomass[mi+h:mf:48])) / dn\n",
    "    ch[h] = (2*sum(coal[mi+h:mf:48])) / dn\n",
    "    gh[h] = (2*sum(gas[mi+h:mf:48])) / dn\n",
    "    gcch[h] = (2*sum(gascc[mi+h:mf:48])) / dn\n",
    "    hh[h] = (2*sum(hydro[mi+h:mf:48])) / dn\n",
    "    nh[h] = (2*sum(nuclear[mi+h:mf:48])) / dn\n",
    "    oh[h] = (2*sum(other[mi+h:mf:48])) / dn\n",
    "    sh[h] = (2*sum(solar[mi+h:mf:48])) / dn\n",
    "    wh[h] = (2*sum(wind[mi+h:mf:48])) / dn\n",
    "    sph[h] = (2*sum(solarpower[mi+h:mf:48])) / dn\n",
    "    wph[h] = (2*sum(windpower[mi+h:mf:48])) / dn\n",
    "    \n",
    "#formatting to make that graph I want (basically need to put things on top of one another)\n",
    "total = nh+hh+bh+oh+sh+wh+gh+gcch+ch\n",
    "    \n",
    "outdic = {'Nuclear':nh, 'Hydrothermal/Biomass/Other':hh+bh+oh, 'Solar':sh, 'New Solar':sph, 'Wind':wh, 'New Wind':wph, 'Gas-CC':gcch, 'Gas':gh, 'Coal':ch, 'Total ERCOT Generation':total}\n",
    "\n",
    "pd.DataFrame(data=outdic).to_excel('FuelHoursJul.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = np.array([31,28,31,30,31,30,31,31,30,31,30,31]); halfhours = days*48; hsums = []\n",
    "months = ['January','February','March','April','May','June','July','August','September','October','November','December']\n",
    "for m in range(12):\n",
    "    hsums.append(sum(halfhours[:m]))\n",
    "hsums.append(17520)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slack by Month\n",
    "slack = pd.read_csv('Slack90.csv',usecols=['Slack']).to_numpy().flatten()\n",
    "\n",
    "months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "daysog = [31,28,31,30,31,30,31,31,30,31,30,31]\n",
    "daysleap = [31,29,31,30,31,30,31,31,30,31,30,31]\n",
    "t = 17520\n",
    "yrhours = [t,t,t] #for leap this would be t + 48\n",
    "baseyear = 2009\n",
    "\n",
    "ms = np.zeros(12)\n",
    "cms = np.zeros(12)\n",
    "ys = np.zeros(3)\n",
    "\n",
    "for halfhour in range(len(slack)):\n",
    "    oghh = halfhour\n",
    "    yi = 0\n",
    "    while halfhour >= yrhours[yi]:\n",
    "        halfhour -= yrhours[yi]\n",
    "        yi += 1\n",
    "    \n",
    "    year = baseyear + yi\n",
    "    \n",
    "    if (year % 4) == 0:\n",
    "        days = daysleap\n",
    "    else:\n",
    "        days = daysog\n",
    "\n",
    "    day = (halfhour // 48) + 1\n",
    "    mi = 0\n",
    "    while day > days[mi]:\n",
    "        day -= days[mi]\n",
    "        mi += 1  \n",
    "    \n",
    "    month = months[mi]\n",
    "    hour = (halfhour % 48) / 2\n",
    "    ys[yi] += slack[oghh]\n",
    "    ms[mi] += slack[oghh]\n",
    "    \n",
    "for halfhour in range(t):\n",
    "    oghh = halfhour\n",
    "\n",
    "    days = daysog\n",
    "    day = (halfhour // 48) + 1\n",
    "    mi = 0\n",
    "    while day > days[mi]:\n",
    "        day -= days[mi]\n",
    "        mi += 1  \n",
    "    \n",
    "    month = months[mi]\n",
    "    cms[mi] += coalhours[oghh]\n",
    "\n",
    "pd.DataFrame(data={'Slack':ms}).to_csv('SlackMonths.csv')   \n",
    "pd.DataFrame(data={'Slack':ys}).to_csv('SlackYears.csv')\n",
    "pd.DataFrame(data={'Coal':cms}).to_csv('CoalMonths.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Study Phase info\n",
    "gisreport = 'Ercot_GIS_Report_June.xlsx'\n",
    "pdat = pd.read_excel(gisreport, sheet_name='Project Details', usecols=['GINR Study Phase','County','Fuel','Capacity (MW)'])\n",
    "\n",
    "sphase = solarp['GINR Study Phase'].to_list()\n",
    "wphase = windp['GINR Study Phase'].to_list()\n",
    "\n",
    "spd = defaultdict(int)\n",
    "wpd = defaultdict(int)\n",
    "\n",
    "for site in solarout:\n",
    "    i = solarnames.index(site)\n",
    "    phase = sphase[i]\n",
    "    #[name,cap] = site.split(' Solar: ')\n",
    "    cap = solarcaps[i]\n",
    "    spd[phase] += float(cap)\n",
    "for site in windout:\n",
    "    i = windnames.index(site)\n",
    "    phase = wphase[i]\n",
    "    #[name,cap] = site.split(' Wind: ')\n",
    "    cap = windcaps[i]\n",
    "    wpd[phase] += float(cap)\n",
    "pd.DataFrame(data=[spd,wpd]).to_excel('StudyPhaseOut.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coal = 'Coal2019.csv'\n",
    "coalhours = pd.read_csv(coal,usecols=['Coal']).to_numpy().flatten()\n",
    "ep = energyprice['HB_HUBAVG'].to_numpy().flatten()\n",
    "r = np.matmul(coalhours,ep)\n",
    "print(r*0.9 / (10**9))\n",
    "#coalhours = np.hstack((coalhours,coalhours,coalhours))\n",
    "coalcf = coalhours / max(coalhours)\n",
    "\n",
    "# pdat = pd.read_csv('Power90.csv')\n",
    "# allpower = pdat['Solar'].to_numpy() + pdat['Wind'].to_numpy()\n",
    "\n",
    "# #print((2.5*10**9)/(sum(coalhours)*0.7))\n",
    "# dif = coalhours - allpower\n",
    "# hc = 0\n",
    "# for i in range(52560):\n",
    "#     if dif[i] > 0:\n",
    "#         hc += 1\n",
    "# print(hc/52560)\n",
    "# coalday = np.empty(48)\n",
    "# for h in range(48):\n",
    "#     pass\n",
    "#    coalday[h] = sum(coalcf[8688+h:10176:48]) / 31\n",
    "\n",
    "#pd.DataFrame(data={'Coal':coalday}).to_csv('CoalJul.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
